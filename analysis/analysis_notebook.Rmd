---
title: "North Santiam Pedigree Project Analysis Notebook"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: false
---

```{r, message = FALSE, warning=FALSE}
require(RLDNe)
require(DHARMa)
require(MASS)
require(lme4)
require(kableExtra)
require(gt)
require(gtsummary)
require(tidyverse)
require(magrittr)
require(countreg)
require(lmerTest)
```


# Summary

This notebook contains a log of all analyses for the 2022 North Santiam Chinook salmon genetic pedigree study. Inference of the pedigree used here is conducted in a separate notebook titled "parentage_assignment_log" in this same repository.

__Goals__  
(1) Summarise assignments    
(2) Estimate total lifetime fitness (TLF) for parent cohorts  
(3) Estimate cohort replacement rates for parent cohorts  
(4) Assess variables that influence fitness with general linear models  
(5) Estimate effective number of breeders using NeEstimator  

This is an R notebook. The .html version of this file is a fully rendered and interactive log. To view it, save the html and open in a browse. The .rmd version can be opened within R studio. To reproduce results or edit the analysis: clone the full repository onto tyour local machine and open the r project in rstudio. This will provide all needed data and objects. 

# Data

## Import
Here we import metadata and the final pedigree.

```{r, message=FALSE, warning=FALSE}
load("../parentage/parentage_results/meta_data.R")
load("../parentage/parentage_results/pedigree.R")

# let's get the metadata on the pedigree
pedigree_meta <- meta_data %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("offspring_", .x)) %>%
  right_join(pedigree, by = c("offspring_sample_id" = "offspring_sample_id"))

#father
pedigree_meta <- meta_data %>%
  select(sample_id, year, type, date, above_below) %>%
  rename_with(.fn = ~ paste0("father_", .x)) %>%
  right_join(pedigree_meta, by = c("father_sample_id" = "father")) %>%
  rename(father = father_sample_id)

#mother
pedigree_meta <- meta_data %>%
  select(sample_id, year, type, date, above_below) %>%
  rename_with(.fn = ~ paste0("mother_", .x)) %>%
  right_join(pedigree_meta, by = c("mother_sample_id" = "mother")) %>%
  rename(mother = mother_sample_id)
```

## Dataset Summary

Here we summarize the metadata of salmon that are part of the final filtered dataset used as candidate parents and offspring.

```{r}

tbl_summary(select(meta_data, type, year), by = type, percent = "row") %>%
  modify_header(label ~ "") %>%
  modify_spanning_header(c("stat_1", "stat_2", "stat_3", "stat_4", "stat_5") ~ "**type**") %>%
  as_kable_extra() %>%
  kable_classic(full_width = F, html_font = "Cambria")# %>%
```
The dataset described above includes all __sampled__ parents from 2011 - 2017 and all __sampled__ offspring from 2014 - 2020, after filtering for missingness and duplicates.

Note: Some of the results we work with in this report are properties of parents, and others are properties of offspring. Throughout the report we include results for parent years 2011-2015, and offspring years for 2016-2020. The pedigree is complete (full age structure present in dataset) for parent years 2011-2015 and for offspring years 2016-2020.  
For example: Fitness is a property of parents and we report fitness for parent years 2011-2015, so it requires information from additional offspring years that are not part of the range of years for which we report offspring level data (2014 and 2015).  
As another example, while 2014 offspring are included in the pedigree, the complete set of their potential parents are not (2009, 2010). This is because we do not include results for parents years 2009 or 2010, but we do include 2011. Similarly 2017 parents are included in the study because they contribute as parents to 2020 offspring year, but we do not sample their potential age 4 and age 5 offspring, so we do not report full 2017 parent level results.

### Releases

Let's summarise outplant release locations by location and date to present in table 2. Only present 2016 and 2017 because table 2 already complete for 2011 - 2015

```{r}
kable(meta_data %>%
  filter(above_below == "above") %>%
    filter(year > 2015) %>%
  count(year, date, location), align = "c", caption = "Table 2 from draft report totals") %>%
  kable_classic(full_width = F, html_font = "Cambria") 

kable(meta_data %>%
  filter(above_below == "above", geno_sex == "F") %>%
    filter(year > 2015) %>%
  count(year, date, location), align = "c", caption = "Table 2 from draft report females") %>%
  kable_classic(full_width = F, html_font = "Cambria") 

kable(meta_data %>%
  filter(above_below == "above", geno_sex == "M") %>%
    filter(year > 2015) %>%
  count(year, date, location), align = "c", caption = "Table 2 from draft report males") %>%
  kable_classic(full_width = F, html_font = "Cambria")

```


# Assignment Rates

This section calculates number of assignments between different parent and offspring classes. 

## Table 3

Here we present the assignment rates into the format of table 3 from the draft report

Each table in the notebook below can be used to recreate table 3. Each table represents a single pair of offspring and parent years. The type of offspring is listed in the first column and the results are split between parent types along the remaining columns (e.g. same format as table 3)

When the "type" of parent varies between two parents, the female parent type is listed first. This is slightly different from table 3, so close attention is required when doing data entry here. For example, if an offspring is assigned to a reintroduced mother and carcass father, the column would be called "reintro/carcass."

```{r}
# the format of the table is difficult to produce in r
# let's not change the format of the table, instead we'll write some helper functions for filling it out 

#let's add a column for the type of assignment, and one for combined types
pedigree_meta %<>%
  mutate(assn_type = case_when((mother == "none" & father == "none") ~ "none",
                               (mother == "none" & father != "none") ~ "male_only",
                               (mother != "none" & father == "none") ~ "female_only",
                               (mother != "none" & father != "none") ~ "pair",)) %>%
  mutate(parent_type = case_when((father_type == mother_type) ~ father_type,
                                 (is.na(father_type) & !(is.na(mother_type))) ~ mother_type,
                                  (is.na(mother_type) & !(is.na(father_type))) ~ father_type,
                                   (father_type != mother_type) ~ paste(mother_type, father_type, sep = "/")))

# function
t4_helper <- function(p_year, off_year){pedigree_meta %>%
  filter(offspring_year == off_year) %>%
  mutate(parent_year = (coalesce(father_year, mother_year))) %>%
  filter(parent_year == p_year) %>%
  mutate(parent_type = as.factor(parent_type)) %>%
  select(offspring_type, parent_type, assn_type) %>%
  tbl_strata(
    strata = parent_type,
    .tbl_fun = ~ .x %>%
      tbl_summary( by = assn_type, percent = NULL)
  ) %>%
  modify_caption(paste(paste("parent year: ", p_year), paste("offspring year: ", off_year), sep = "  ,")) %>%
  as_kable_extra() %>%
  kable_classic(full_width = F, html_font = "Cambria")
}
```

### Offspring Year 2016
```{r}
#t4 helper function example
t4_helper("2011", "2016")
t4_helper("2012", "2016")
t4_helper("2013", "2016")
```

### Offspring Year 2017
```{r }
t4_helper("2012", "2017")
t4_helper("2013", "2017")
t4_helper("2014", "2017")
```

### Offspring Year 2018
```{r}
t4_helper("2013", "2018")
t4_helper("2014", "2018")
t4_helper("2015", "2018")
```

### Offspring Year 2019
```{r}
t4_helper("2014", "2019")
t4_helper("2015", "2019")
t4_helper("2016", "2019")
```

### Offspring Year 2020
```{r}
t4_helper("2015", "2020")
t4_helper("2016", "2020")
t4_helper("2017", "2020")
```

## Age at Maturity

We can also calculate age at maturity for offspring year using these data. These results appear in the draft report in the text, but we will summarise here in a table and a figure

```{r, message=FALSE, warning=FALSE}

# report text is formatted as number and percent per age for each offspring year

kable(pedigree_meta %>%
        filter(!(offspring_year %in% c("2014", "2015"))) %>%
  mutate(parent_year = (coalesce(father_year, mother_year))) %>%
  filter(!(is.na(parent_year))) %>%
  mutate(age = as.numeric(offspring_year) - as.numeric(parent_year)) %>%
  group_by(offspring_year, age) %>%
  summarise(n = n()) %>%
  mutate(percent = 100*(n/sum(n))), digits = 0) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) %>%
  collapse_rows(columns = 1)
  
  
```

```{r, message=FALSE, warning=FALSE}
aam_data <- pedigree_meta %>%
        filter(!(offspring_year %in% c("2014", "2015"))) %>%
  mutate(parent_year = (coalesce(father_year, mother_year))) %>%
  filter(!(is.na(parent_year))) %>%
  mutate(age = as.numeric(offspring_year) - as.numeric(parent_year)) %>%
  group_by(offspring_year, age) %>%
  summarise(n = n()) %>%
  mutate(percent = 100*(n/sum(n)))

ggplot(data = aam_data)+geom_bar(aes(x = offspring_year, color = as.factor(age), fill = as.factor(age), y = n), stat = "identity", position = "dodge")+scale_fill_viridis_d(name = "Age")+scale_colour_viridis_d(name = "Age")+theme_bw()+xlab("Offspring Year")+ggtitle("Age at Maturity")


```



# Total Lifetime Fitness

In this section, we calculate the number of offspring assigned to parents from the pedigree and calculate summary statistics.

```{r}
#first let's get a dataframe that can be easily used to calculate parent level information
# all candidate parents, the number of time they appear in the pedigree and their metadata

parents <- meta_data %>%
  filter(year %in% 2011:2017) #checked this against the input parent lists, same size

father_counts <- pedigree %>%
  group_by(father) %>%
  count() %>%
  rename(parent = father)

mother_counts <- pedigree %>%
  group_by(mother) %>%
  count() %>%
  rename(parent = mother)

parent_counts <- bind_rows(mother_counts, father_counts) 
rm(mother_counts)
rm(father_counts)

parents %<>%
  left_join(parent_counts, by = c("sample_id" = "parent")) %>%
  rename(tlf = n) %>%
  mutate(tlf = replace_na(tlf, 0))
```

## Table 4
Here we format the TLF results to match table 4 of the draft report.

```{r, message=FALSE, warning=FALSE}
kable(parents %>%
  group_by(year, type, geno_sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))), align = "c", caption = "Total Lifetime Fitness by Parent Group and Sex") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) %>%
  collapse_rows(columns = 1, valign = "top") %>%
  scroll_box(height = "400px")


```

## Results Text

The results in text combine estimates of TLF across sexes. Let's generate the table above again, without splitting moms and dads.

```{r, message=FALSE, warning=FALSE}
kable(parents %>%
  group_by(year, type) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))), align = "c", caption = "Total Lifetime Fitness by Parent Group") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) %>%
  collapse_rows(columns = 1, valign = "top")

```


## Notes

### Math Check
The math here can get a little funky because we combine duo and trio assignments. Let’s manually calculate the values here from the pedigree and check that they match the output of the notebook code above.

Among the 149 outplants in 2011, 72 were female and 77 were male. There were 94 total offspring (18, 33, and 43 in 2014, 2015 and 2016 respectively). Of the 94 total offspring 84 were assigned to a mother and 67 were assigned to a father for fitness female = 1.21 and fitness male = 0.87.

For overall mean fitness we cannot simply divide the number of offspring by number of parents like above because some offspring are assigned to two parents while others are assigned to two. Instead we sum the TLF of each parent and divide by the number of parents. In 2011 the sum of TLF across individual parents is 149 for overall mean fitness of 1. Instead of using the code above here, I combined mothers and fathers from the pedigree and summed 2011 outplants. 
Calculating fitness this way, if all assignments were trios we need a fitness of 2 to reach an overall CRR of 1.

All looks good!

### 2015 comparisons

We should probably build a more complex model here, but for now let's do a one-liner analysis to see if 2015 reintros above did significantly better than reintros below or outplants above.

```{r}

summary(aov(data = filter(parents, year == 2015, type %in% c("outplant", "reintro_above", "reintro")), tlf ~ type))
TukeyHSD(aov(data = filter(parents, year == 2015, type %in% c("outplant", "reintro_above", "reintro")), tlf ~ type))
```

NOR salmon had significantly higher fitness HOR salmon in the above Detroit habitat according to ANOVA, but not compared to NOR salmon reintroduced to below Big Cliff. Note this result should NOT be trusted, ANOVA on overdispersed count data is inappropriate. Need to build a GLM here. Will consider taking the time to do this after draft is complete. Also the factors are mispecified, rather than compare the three groups, the effects of origin and habitat should treated as separate factors

# Cohort Replacement Rates

Here we estimate the cohort replacement rate across different groups of parents. 

Results are prepared for each of the following groups:   

* Outplants (Above Detroit)   
* Reintroductions (Below Big Cliff)  
* Reintroductions (Above Detroit)  


Within each of the above, calculate for each parent year and each sex. 

```{r, message = FALSE, warning = FALSE}
# data wrangling here is very similar to TLF, maybe we can save some work and use it again

# add offspring sex to pedigree_meta
full_meta <- readxl::read_xlsx("../parentage/parentage_data/full_dataset.xlsx", sheet = 1, col_types = "text")

pedigree_meta %<>%
  left_join(select(full_meta, geno_sex, sample_id), by = c("offspring_sample_id" = "sample_id")) %>%
  mutate(offspring_sex = geno_sex)

father_male_offspring_counts <- pedigree_meta %>%
  filter(offspring_sex == "M") %>%
  group_by(father) %>%
  count() %>%
  rename(parent = father)

mother_female_offspring_counts <- pedigree_meta %>%
  filter(offspring_sex == "F") %>%
  group_by(mother) %>%
  count() %>%
  rename(parent = mother)

parent_counts_same_sex <- bind_rows(mother_female_offspring_counts, father_male_offspring_counts) 
rm(father_male_offspring_counts)
rm(mother_female_offspring_counts)

parents %<>%
  left_join(parent_counts_same_sex, by = c("sample_id" = "parent")) %>%
  rename(same_sex_offspring = n) %>%
  mutate(same_sex_offspring = replace_na(same_sex_offspring, 0))

kable(parents %>%
  group_by(year, type, geno_sex) %>%
  summarise(crr = sum(same_sex_offspring)/n()), align = "c", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) %>%
  scroll_box(height = "400px")
# Let's check one of these to make sure the code is working correctly. In 2016, there were 452 male outplants. These 452 potential fathers appear in the final pedigree 1092 times. Of these 1092 offspring, 723 is male. Therefore the correct CRR for 2016 male outplants is 1.5995575. This matches the table.
```

The results test also presents the numerator and denominator of CRR not split by sex, but doesn't call it CRR or do the calculation (just presents the number of outplant parents and the number of offspring assigned to them - for good reason as this could paint an overly rosey picture with uneven sex ratios). Let's sum these below, so it is easier to write this result section. 

```{r, message=FALSE, warning=FALSE}
a <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  filter(father_type == "outplant" | mother_type == "outplant") %>% 
  group_by(parent_year) %>%
  summarise(offspring_n = n())

b <- full_meta %>%
  filter(type == "outplant") %>%
  count(year) %>%
  rename(parent_year = year, n_outplants = n)

kable(left_join(a,b), align = "c", caption = "total number of offspring that assign to outplants per parent year") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)


```

The results text also splits the results above according to carcass and non-carcass.

```{r, message=FALSE, warning=FALSE}
a <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  filter(father_type == "outplant" | mother_type == "outplant") %>% 
  group_by(parent_year, offspring_type) %>%
  summarise(offspring_n = n())

b <- full_meta %>%
  filter(type == "outplant") %>%
  count(year) %>%
  rename(parent_year = year, n_outplants = n)

kable(left_join(a,b), align = "c", caption = "total number of offspring that assign to outplants per parent year") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)


```

There are also CRR results presented for Reintros in the text, so we need to combined across sex values here too.


```{r, message=FALSE, warning=FALSE}
a <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  filter(father_type == "reintro" | mother_type == "reintro") %>% 
  group_by(parent_year) %>%
  summarise(offspring_n = n())

b <- full_meta %>%
  filter(type == "reintro") %>%
  count(year) %>%
  rename(parent_year = year, n_reintros = n)

kable(left_join(a,b), align = "c", caption = "total number of offspring that assign to reintros per parent year") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)


```

Also need the split into carcass and live:

```{r, message=FALSE, warning=FALSE}
a <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  filter(father_type == "reintro" | mother_type == "reintro") %>% 
  group_by(parent_year, offspring_type) %>%
  summarise(offspring_n = n())

b <- full_meta %>%
  filter(type == "reintro") %>%
  count(year) %>%
  rename(parent_year = year, n_reintros = n)

kable(left_join(a,b), align = "c", caption = "total number of offspring that assign to reintros per parent year") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)


```


And finally, the 2015 above Detroit reintros (in a future revision of this notebook, consider combining all of these into a single table)

```{r, message=FALSE, warning=FALSE}
a <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  filter(father_type == "reintro_above" | mother_type == "reintro_above") %>% 
  group_by(parent_year) %>%
  summarise(offspring_n = n())

b <- full_meta %>%
  filter(type == "reintro_above") %>%
  count(year) %>%
  rename(parent_year = year, n_reintros_above = n)

kable(left_join(a,b), align = "c", caption = "total number of offspring that assign to reintros above Detroit per parent year") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)


```

Also need the split into carcass and live:

```{r, message=FALSE, warning=FALSE}
a <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  filter(father_type == "reintro_above" | mother_type == "reintro_above") %>% 
  group_by(parent_year, offspring_type) %>%
  summarise(offspring_n = n())

b <- full_meta %>%
  filter(type == "reintro_above") %>%
  count(year) %>%
  rename(parent_year = year, n_reintros = n)

kable(left_join(a,b), align = "c", caption = "total number of offspring that assign to reintros above Detroit per parent year") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)


```

# Predictors of Fitness

Here we fit some GLMs on fitness of outplanted salmon. We split the analysis below into two full model specifications: the specification from the draft report and a different model that might have more power to detect significant effects of variables on fitness. 

## Fixed Predictors (GLM)

First we fit the model the same way as the draft report. For each outplant year, Total lifetime fitness ~ sex + release location + release date. All are fixed effects and all but date are factors (categorical). The GLM family is Poisson (log link function, Poisson distribution) and the GLM is evaluated using likelihood ratio test (chi-squared distribution) and individual levels of effects are evaluated with a Wald Tests (automatically done by R so included below) and likelihood-ratio tests (to match what was done previously). 

I also went a little further than what was done before:  
I did model validation by (a) comparing the scaled residuals against rank transformed predicted values and (b) examining a QQ plot for goodness of fit (Kolmogorov–Smirnov test), overdispersion, and outliers. This was added to the report draft. The previous analysis conducted model validation using a Chi-squared goodness of fit test using Pearson residuals. The models failed the test (and therefore model validation) in every year, but this was not reported in the draft.

I also went a little further here, but did not include the follwoing in the report draft. For years with significant full models and significant effects, we conducted stepwise model selection by AIC to find a sparse final model, assessed significance of predictor variables in the final model using a likelihood-ratio test, and assessed significance of individual levels of predictors using a Wald test.  

__Some other notes:__  
Note 1:  
The previous workers on this project (Evans, Black, Bohn) all used jmp to fit this model. Specifically, in the previous North Santiam (and South Santiam) reports jmp was used to fit a glm with a poisson distribution. However, the data is a poor fit to the distribution: in each year the response variable demonstrates significant overdispersion. Sard solved this problem by fitting their models using a negative binomial in McKenzie, but previous workers on Santiam adjusted the tests using an "overdispersion parameter estimated by Pearson Chisq/DF." This approach is implemented in the R glm() function by using the "quasipoisson" rather than poisson family for the glm fit, but the authors of the most populat r packages for fitting GLMs believe it is inappropriate to output AIC or likelihood using this "quasipoisson" distribution, while the jmp authors don't seem to have an issue with reporting AIC/likelihoods when the response variable demonstrates overdispersion and report it. Table 5 reports to log-likelihood ratio of individual effects so to get the table with the exact same results, so we need to make a decision here.


I'd prefer to take the approach Sard took and fit with a different distribution (negative binomial). This seems to be the best compromise between getting this done in a timely manner, and limiting the changes to the previous approach. I take this approach below.

Alternatively we could (a) take the time to figure out how to run jmp, (b) use the quasipoisson (approach from before), but eliminate the log-likelihood ratio from table 5 and only report the p values.

Note 2:  
In my original interpretation of the methods section and logs I thought the previous model fits in JMP fit release date as a fixed factor. When I found the actual data provided to JMP I found that Bohn had converted release date to Julian day (continuous numerical predictor). This is a huge relief for interpreting the results, but still isn't optimal, because it doesn't take into account the contribution to variance of batch effects of release dates, only considers a linear relationship between julian day and log(TLF). A mixed model can do both (random batch effects + fixed effect of Julian day).  
Also, we are ignoring non-linear relationships. What if Julian day is strongly predictive of fitness but not linear - e.g. stabilizing selection with greatest fitness observed in the middle of the distribution but poor fitness at extremes. We don't explore this possibility in the current approach. 

Note 3:  
The draft report methods state that interaction terms are fit in the model, but the results table shows model fits without interaction terms. Was there some stage of analysis where the model fits were analyzed with and without interaction terms (i.e. model selection)? Was the data examined for a potential interaction between release date and sex? How was this decision made? It seems like if the likelihood ratio test for interaction term was not significant it was dropped from the model. Should I take the same approach if we decide to leave this part of the report exactly as is? I did not fit the interaction term to follow what was done in the final version of the results, but when we discuss changing this part of the report we should discuss this.

__Approach Outline__  
For each of the years below, I first present the structure of the data to determine if the full model can be fit. Then I fit the full model and test it using a log-likelihood ratio test against a null model that contains only an intercept. If there is a signifcant global/full model and evidence that predictors have significant effect (Wald test + likelihood ratio test), then I proceed to model validation and model selection and present estimates of effects of predictors of fitness.



### 2011
```{r}
# data
glm_2011_data <- parents %>%
  filter(type == "outplant", year == "2011") %>%
  select(date, geno_sex, location, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>%
  mutate(date = as.factor(date), geno_sex = as.factor(geno_sex), location = as.factor(location))

str(glm_2011_data)
```

For 2011, there is only a single release location and 3 dates. We will not include location in the model.

Let's fit the model and test for global significance. 
```{r}
#glm_2011 <- glm.nb(tlf ~ geno_sex + date +geno_sex*date , data = glm_2011_data)
glm_2011_full <- glm.nb(tlf ~ geno_sex + jday  , data = glm_2011_data)
glm_2011_null <- glm.nb(tlf ~ 1 , data = glm_2011_data)

# test for global
anova(glm_2011_null, glm_2011_full, test = "Chisq")
summary(glm_2011_full)
```

Let's conduct LR tests on each predictor.

```{r}
dropterm(glm_2011_full, test = "Chisq")
```



The global model is insignificant and Wald and LR Tests of each predictor are not significant. Do not proceed with model selection.

### 2012
```{r}
# data
glm_2012_data <- parents %>%
  filter(type == "outplant", year == "2012") %>%
  select(date, geno_sex, location, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>%
  mutate(date = as.factor(date), geno_sex = as.factor(geno_sex), location = as.factor(location))

str(glm_2012_data)
```

For 2012, we will fit the full model

Let's fit the model and test for global significance. 
```{r}
#glm_2011 <- glm.nb(tlf ~ geno_sex + date +geno_sex*date , data = glm_2011_data)
glm_2012_full <- glm.nb(tlf ~ geno_sex + jday + location  , data = glm_2012_data)
glm_2012_null <- glm.nb(tlf ~ 1 , data = glm_2012_data)

# test for global
anova(glm_2012_null, glm_2012_full, test = "Chisq")
summary(glm_2012_full)
```

Let's conduct LR tests on each predictor.

```{r}
dropterm(glm_2012_full, test = "Chisq")
```

The global model is insignificant and Wald Tests of each predictor are not significant. Do not proceed with model selection

### 2013
```{r}
# data
glm_2013_data <- parents %>%
  filter(type == "outplant", year == "2013") %>%
  select(date, geno_sex, location, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>%
  mutate(date = as.factor(date), geno_sex = as.factor(geno_sex), location = as.factor(location))

str(glm_2013_data)
```

For 2013, we will fit the full model

Let's fit the model and test for global significance. 
```{r}
#glm_2011 <- glm.nb(tlf ~ geno_sex + date +geno_sex*date , data = glm_2011_data)
glm_2013_full <- glm.nb(tlf ~ geno_sex + jday + location , data = glm_2013_data)
glm_2013_null <- glm.nb(tlf ~ 1 , data = glm_2013_data)

# test for global
anova(glm_2013_null, glm_2013_full, test = "Chisq")
summary(glm_2013_full)
```

Let's conduct LR tests on each predictor.

```{r}
dropterm(glm_2013_full, test = "Chisq")
```

The global model is insignificant and Wald and LR Tests of each predictor are not significant. Do not proceed with model selection.


### 2014
```{r}
# data
glm_2014_data <- parents %>%
  filter(type == "outplant", year == "2014") %>%
  select(date, geno_sex, location, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>%
  mutate(date = as.factor(date), geno_sex = as.factor(geno_sex), location = as.factor(location))

str(glm_2014_data)
```

For 2014, we will fit the full model

Let's fit the model and test for global significance. 
```{r}
#glm_2011 <- glm.nb(tlf ~ geno_sex + date +geno_sex*date , data = glm_2011_data)
glm_2014_full <- glm.nb(tlf ~ geno_sex + jday + location   , data = glm_2014_data)
glm_2014_null <- glm.nb(tlf ~ 1 , data = glm_2014_data)

# test for global
anova(glm_2014_null, glm_2014_full, test = "Chisq")
summary(glm_2014_full)
```

Let's conduct LR tests on each predictor.

```{r}
dropterm(glm_2014_full, test = "Chisq")
```


The global model is insignificant and but sex has a significant effect (according to Wald Test and LRT). Do not proceed with model selection as this could lead to overfitting (global model not significant). Let's do model validation though.


```{r}
simulationOutput <- simulateResiduals(fittedModel = glm_2014_full, plot = F)
plot(simulationOutput)
```

Model is a poor fit to the data, likely due to outliers. Because we are dealing with count data, we might need a different approach to making sure outliers are the true source of problem and not model mispecification, but in any case there is dependence between the predicted values and the residuals and the qqplot reveals some issues. The model fit in JMP also failed validation, but the result was not reported. 


Let's convert the paramter estimate to something more easy to interpret (invert the tranformation back to fitness)

```{r}
exp(coef(glm_2014_full))


```

Males have predicted 57% fitness of females in 2014.

My take is that this absolutely should not be included in the draft as a significant effect of sex. We are violating model assumptions. If we are committed to the modeling approach as is, we should explore why model validation failed and evaluate how severe of a problem we are dealing with. Maybe we're comfortable with this level of goodness of fit? Alternatively, maybe the model needs to be specified differently or we need to remove outliers. 

### 2015
```{r}
# data
glm_2015_data <- parents %>%
  filter(type == "outplant", year == "2015") %>%
  select(date, geno_sex, location, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>%
  mutate(date = as.factor(date), geno_sex = as.factor(geno_sex), location = as.factor(location))

str(glm_2015_data)
```

For 2015, we will fit the full model

Let's fit the model and test for global significance. 
```{r}
#glm_2011 <- glm.nb(tlf ~ geno_sex + date +geno_sex*date , data = glm_2011_data)
glm_2015_full <- glm.nb(tlf ~ geno_sex + jday + location  , data = glm_2015_data)
glm_2015_null <- glm.nb(tlf ~ 1 , data = glm_2015_data)

# test for global
anova(glm_2015_null, glm_2015_full, test = "Chisq")
summary(glm_2015_full)
```

Let's conduct LR tests on each predictor.

```{r}
dropterm(glm_2015_full, test = "Chisq")
```

Global model is significant. Sex has signifcant effect by Wald and LRT. Let's do model validation.

```{r}
simulationOutput <- simulateResiduals(fittedModel = glm_2015_full, plot = F)
plot(simulationOutput)
```

This model also has some issues, though less severe. The magnitude of residuals is not independent of the fitted values. For fun, let's see if one variable is causing the problem.

```{r}
plotResiduals(simulationOutput, form = glm_2015_data$geno_sex)
plotResiduals(simulationOutput, form = glm_2015_data$location)
plotResiduals(simulationOutput, form = glm_2015_data$jday)

```

Nope, all looks good. Let's save further diagnosis until after we get the first draft (exactly as done before) completed.

We will do model selection though, since it is quick.

```{r,  results='hide'}
msl_2015 <- stepAIC(glm_2015_full, direction = "backward")
msl_2015$anova
anova(msl_2015)
simulationOutput <- simulateResiduals(fittedModel = msl_2015, plot = F)
plot(simulationOutput)
```

The best final model using stepwise model selection on AIC includes sex and location. It appear getting rid of Julian day solved the model fit issues.Let's take a look at the coefficients from this model.

```{r}
summary(msl_2015)
```

 I'll convert the coefficients into something easier to understand by taking the inverse of the log transformation of the effects (e.g. exp(parameter estimate)).

```{r}
exp(glm_2015_full$coefficients)
```

Males have predicted 72% of females in 2015 and Dry Creek is better than Breitenbush


## GLMs (Dayan)

I think the most powerful approach may be to use a mixed model, however (1) GLMMs on overdispersed count data are getting into some very recently developed statistics and might be challenging and (2) there are still improvements we can make to the GLMs without incorporating random effects.

In the previous GLM section I attempted to follow what had been done previously. In this section I give myself the same freedom it seems other workers have had when trying to model fitness and explore additional covariates and distributions, I also update the model selection and validation approach, given recent developments in best practices for GLMs.

### Outline

(1) EDA - let's look at the data in greater detail before jumping into modeling.  
(2) Choose covariates - do some preliminary model fits and see if we're missing anything. For example in the mixed model approach where we combine year, we may see that the sex effect is actual due to skewed sex ratios, therefore we can assume that an important interaction term between sex and sex ratio of outplanting that year is missing from the model, leading to poor fit and overdispersion. Can we think of what might be missing from the model?  
(3) Choose Distribution - fit full models of Poisson, Quasi-Poisson, NB, ZIP, ZINB and Hurdle models. Does this fix the overdispersion? Make the residuals look good?  
(4) Model selection and validation on the final model.

We'll do our full exploration using 2014 data.

### EDA

First let's look closely at the distribution of the response variable
```{r, message=FALSE, warning=FALSE}
ggplot(data = glm_2014_data)+geom_histogram(aes(x = tlf))+theme_classic()
```

Hard to imagine something more zero inflated than that. No wonder the Poisson, Quasi-Poisson and NB models had a hard time. 

Next let's look at some biplots.



```{r}
##################################################################
##################################################################
#Here are some functions that we took from the pairs help file and
#modified, or wrote ourselves. To cite these, use the r citation: citation()

panel.cor <- function(x, y, digits=1, prefix="", cex.cor = 6)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r1=cor(x,y,use="pairwise.complete.obs")
  r <- abs(cor(x, y,use="pairwise.complete.obs"))
  txt <- format(c(r1, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) { cex <- 0.9/strwidth(txt) } else {
     cex = cex.cor}
  text(0.5, 0.5, txt, cex = cex * r)
}

##################################################################
panel.smooth2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
                        cex = 1, col.smooth = "black", span = 2/3, iter = 3, ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok))
    lines(stats::lowess(x[ok], y[ok], f = span, iter = iter),
          col = 1, ...)
}

##################################################################
panel.lines2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
                       cex = 1, ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok)){
    tmp=lm(y[ok]~x[ok])
    abline(tmp)}
}

##################################################################
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
}

pairs(select(glm_2014_data, tlf, geno_sex, jday, location), lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)


```

Location and jday will cause some problems. It seems the release location is confounded with the release date. Everything else here looks okay-ish. Will it help us to consider log(tlf).

```{r}
select(glm_2014_data, tlf, geno_sex, jday, location) %>%
  mutate(tlf = log(tlf+1)) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)
```

Let's also look at the data zero-truncated. Some patterns might be hiding in there but we are blinded by the large number of zeros

```{r}
select(glm_2014_data, tlf, geno_sex, jday, location) %>%
 filter(tlf !=0) %>%
  mutate(tlf = log(tlf)) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)
```

The big takeaways here are:  
* we should be wary of instability of parameter estimates of any model that includes both location and jday, because of strong collinearity. Since one is a caterogical we can use the VIF function from the car package to estimate generalized VIFs to evaluate how severe of a problem this is. 

### Which covariates

__Density__
The first one I can thnk of to pull out the available data is density: How many fish were outplanted at once. Let's look at this variable.

```{r}
glm_2014_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

d2014 <- glm_2014_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

glm_2014_data %<>%
  left_join(d2014)

select(glm_2014_data, tlf, geno_sex, jday, location, density) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)
```

Theres a lot of variation in outplanting density, and, perhaps not surprisingly, a relationship between density and julian day and location.

__Julian Day__
I'm also curious about whether the jday covariate should be included as a linear continous predictor. This doesn't seem to make a lot of biological sense. Let's look closely at the distribution and it's relationship to tlf.

```{r}
ggplot(glm_2014_data)+geom_smooth(aes(jday, tlf), span = 0.5)+geom_point(aes(jday, tlf))
```

Hard to tell. Let's transform, zero-truncate and try again.

```{r}
ggplot(filter(glm_2014_data, tlf !=0))+geom_smooth(aes(jday, log(tlf)), span = 0.5)+geom_point(aes(jday, log(tlf)))
```

Well, nothing pops out of a simple LOESS with no covariates, but it's still a possibility. This is best evaluated using models.

```{r}
M2014_NB <- glm.nb(tlf ~ geno_sex + jday + location+  geno_sex*jday + density +density*geno_sex , data = glm_2014_data)
M2014_NB_non_linear <-  glm.nb(tlf ~ geno_sex + poly(jday,2, raw = TRUE) + location + density +density*geno_sex  , data = glm_2014_data)
summary(M2014_NB)
summary(M2014_NB_non_linear)
```

No, we do not benefit from fitting jday as quadratic.

Let's do the same comparison for density, as this could also have a non-linear relationship.

```{r}
ggplot(filter(glm_2014_data, tlf !=0))+geom_smooth(aes(density, log(tlf)))+geom_point(aes(density, log(tlf)))

ggplot(filter(glm_2014_data))+geom_smooth(aes(density, (tlf)))+geom_point(aes(density, (tlf)))
```

```{r}
M2014_NB <- glm.nb(tlf ~ geno_sex + jday + location+  geno_sex*jday + density +density*geno_sex , data = glm_2014_data)
M2014_NB_non_linear <-  glm.nb(tlf ~ geno_sex + jday + location  + poly(density,2) +  poly(density,2)*geno_sex  , data = glm_2014_data)
summary(M2014_NB)
summary(M2014_NB_non_linear)
```

```{r}
bind_cols(AIC(M2014_NB_non_linear, M2014_NB), BIC(M2014_NB_non_linear, M2014_NB)) %>%
  select(df = df...1, AIC, BIC)

anova( M2014_NB_non_linear, M2014_NB )
```

Including density as a quadratic improves model fit according to AIC, BIC and LRT, but the improvement is small and only marginaly significant. I think the right thing to do here is to fully explore the possibility of non-linear effects of density using the actual data for each year. Fro the 2014 data, which we use to explore the distributions for fitting, we will include a quadratic. 



### Distributions

Let's fit some models! I skip some exploration of some interaction terms, but in general the approach here is to fit a model, do some model selection, and conduct model validation for different distributions. Then I compare the model fits using AIC, LRTs and examining the residuals.

##### Poisson
```{r}
M2014_P <- glm(tlf ~ geno_sex + jday + location +poly(density,2)+  geno_sex*jday + geno_sex*poly(density,2) , data = glm_2014_data, family = poisson)

summary(M2014_P)  

AER::dispersiontest(M2014_P)
```

Welp, it looks the additional covariate is important but didn't solve our overdispersion problem. The residual deviance is less than the degrees of freedom, and both the density and density*sex interaction have very significant z-statistics. Let's do some model selection before moving on.

```{r}
drop1(M2014_P, test = "Chi")
```

The drop1 approach suggests just the interaction between sex and density is significant. This suggests the final model should include only the two fixed effects and their interaction. Let's also do this with Wald Tests

```{r}
M2014_P2 <-  glm(tlf ~ geno_sex + jday  +poly(density,2)+  geno_sex*jday + geno_sex*poly(density,2), family = poisson, data = glm_2014_data) # first drop location
summary(M2014_P2)

# then sex
M2014_P3 <-  glm(tlf ~ geno_sex + jday +poly(density,2)+ geno_sex*poly(density,2) , data = glm_2014_data, family = poisson) # then jday/sex interaction
summary(M2014_P3)

M2014_P4 <-  glm(tlf ~ geno_sex  +poly(density,2)+ geno_sex*poly(density,2)  , data = glm_2014_data, family = poisson) # now jday
summary(M2014_P4)
```

Both model selection approaches produce the same result. Let's look at the model fit.

```{r}

plot(M2014_P4)

EP <- resid(M2014_P4, type = "pearson")
mu <- predict(M2014_P4, type = "response")
plot(x = mu, y = EP, main = "Pearson residuals")


```

Also plot residuals against predictors.
```{r}
ggplot()+geom_boxplot(aes( y = resid(M2014_P4, type = "pearson"), x =M2014_P4$data$geno_sex))


ggplot()+geom_point(aes( y = resid(M2014_P4, type = "pearson"), x =M2014_P4$data$density))+geom_smooth(aes( y = resid(M2014_P4, type = "pearson"), x =M2014_P4$data$density))

ggplot()+geom_point(aes( y = resid(M2014_P4, type = "pearson"), x =M2014_P4$data$density, color = M2014_P4$data$geno_sex))+geom_smooth(aes( y = resid(M2014_P4, type = "pearson"), x =M2014_P4$data$density, color = M2014_P4$data$geno_sex))

```

We'll also try the DHARMa approach, as the expectations for the model validation using Pearson or plain residuals is complicated for a Poisson GLM

```{r}
simulationOutput <- simulateResiduals(fittedModel = M2014_P, plot = F)
plot(simulationOutput)
testZeroInflation(simulationOutput)
#plotResiduals(simulationOutput,  glm_2014_data$geno_sex)
```



We'll discuss these plots in the summary section. Let's collect a little more info. 

First, how does this model compare to a a null model, and how does it compare to the best model without density (e.g. the approach taken before). 

```{r}
M2014_Pnull <- glm(tlf ~ 1 , data = glm_2014_data, family = poisson)
anova(M2014_Pnull,M2014_P4, test = "Chisq")
```

The final model is a substantially better fit to the data than a null model.

```{r}
M2014_Pno_dens_full <- glm(tlf ~ geno_sex + location+ jday+geno_sex*jday , data = glm_2014_data, family = poisson)
summary(M2014_Pno_dens_full)
drop1(M2014_Pno_dens_full, test = "Chisq")
```

The best model without density is jday + sex and their interaction. Model validation for this model is below.

```{r}
M2014_Pno_dens_final <- glm(tlf ~ geno_sex  +jday+geno_sex*jday , data = glm_2014_data, family = poisson)
summary(M2014_Pno_dens_final)
plot(M2014_Pno_dens_final)
```


__Summary of Poisson fit__

These results suggest adding the density covariate was very important, but we still have an overdispersion problem. QQplots for Poisson will always be problematic, but the DHARMa approach can help us interpret what's going on.

It seems to me that we are dealing with overdispersion due to zero inflation, but it will be hard to tell without fitting a zero-inflated model and negative binomial. The model is struggling between fitting all the zeros and fitting the tlf > 1. This could explain the break in the qqplot, the DHARMa residuals being worse at higher predicted values and potentially the overdispersion. 

##### NB

Let's skip the quasipoisson and jump straight to negative binomial.

```{r}
M2014_NB <- glm.nb(tlf ~ geno_sex + jday + location +poly(density,2)+  geno_sex*jday + geno_sex*poly(density,2) , data = glm_2014_data)

summary(M2014_NB)  

```


```{r}
drop1(M2014_NB, test = "Chi")
```

```{r}
M2014_NB2 <-  glm.nb(tlf ~ geno_sex + jday +poly(density,2)+  geno_sex*jday + geno_sex*poly(density,2) , data = glm_2014_data) # first drop location
summary(M2014_NB2)

# then sex
M2014_NB3 <-  glm.nb(tlf ~ geno_sex + jday + poly(density,2) + geno_sex*poly(density,2) , data = glm_2014_data) # then jday/sex interaction
summary(M2014_NB3)

M2014_NB4 <-  glm.nb(tlf ~ geno_sex  +poly(density,2)+ poly(density,2) , data = glm_2014_data) # now jday
summary(M2014_NB4)
```

Same results as for the Poisson so far. Model selection by both Wald tests and LRT suggests a final model with sex, density and their interaction.  Let's look at the model fit.

```{r}

plot(M2014_NB4)

EP <- resid(M2014_NB4, type = "pearson")
mu <- predict(M2014_NB4, type = "response")
plot(x = mu, y = EP, main = "Pearson residuals")


```


```{r}
simulationOutput <- simulateResiduals(fittedModel = M2014_NB4, plot = F)
plot(simulationOutput)
testZeroInflation(simulationOutput)
#plotResiduals(simulationOutput,  glm_2014_data$geno_sex)
```

```{r}
AIC(M2014_P4, M2014_NB4)
```

__Summary NB__

Allowing for separate variance and mean estimation (e.g. poisson -> negative binomial) looks like it improved the fit substantially. We no longer see evidence of overdispersion. The only flag comes from DHARMa's outlier test, but the leverage plot suggests nothing too severe is going on. This model fit looks good.  

##### Zero inflation - ZIP

I choose to examine mixture models as well as two-part/hurdle models. I think the zeros include both true and false values and given the low mean fitness in the system, I expect many parents to produce zero offspring and for our covariates to have some impact, therefore a mixture model is probably a better fit. Here we fit a zero inflated poisson.

For the zero-inflation models I fit the binomial/logit part of the model with an intercept only, since the zeros I'm trying to model here have nothing to do with our covariates.


```{r}
M2014_ZIP <- zeroinfl(tlf ~ geno_sex + jday + location +poly(density,2)+  geno_sex*jday + geno_sex*poly(density,2) | 1, data = glm_2014_data)
summary(M2014_ZIP)

```

Already we are seeing something interesting here. 

Instead of model selection on a ZIP, we'll assume the same covariates are important from the poisson side of the model. 

Same results.

```{r}
M2014_ZIP4 <- pscl::zeroinfl(tlf ~ geno_sex +poly(density,2) + geno_sex*poly(density,2) | 1, data = glm_2014_data)
summary(M2014_ZIP4)
```

There is no automatic model validation plot method built into the plot function, so let's do it ourselves.

```{r}
plot(fitted(M2014_ZIP4), resid(M2014_ZIP4, type = "pearson"))
```


##### Zero-inflation ZINB



```{r}
M2014_ZINB <- zeroinfl(tlf ~ geno_sex + jday + location +poly(density,2)+  geno_sex*jday + geno_sex*poly(density,2) |1 , data = glm_2014_data, dist = "negbin")

summary(M2014_ZINB)
```

Now we can check if the ZIP model solves the problem of overdispersion. 


```{r}
lrtest( M2014_ZIP, M2014_ZINB)
```

This overwhelmingly suggests that the zero inflated NB is better than zero-inflated model. Let's not take the time to learn model selection for right now and assume the same model as non-zero-inflated models so far

```{r}
# can't easily use the drop1 function here, let's conduct some LRTs 
# we'll use the wald test do make some informed decisions
M2014_ZINB4 <- zeroinfl(tlf ~ geno_sex  +poly(density,2) + geno_sex*poly(density,2) |1 , data = glm_2014_data, dist = "negbin") #jday worst in both sides of the model
lrtest(M2014_ZIP4, M2014_ZINB4)


summary(M2014_ZINB4)
```

Here the zero-inflation part of the model isn't doing much. The NB is catching most of the overdispersion we observed earlier

##### Zero inflation hurdle nb

For the Hurdle we need to include the covariates on the zero part of the model.

```{r}
M2014_HNB4 <- hurdle(tlf ~ geno_sex  +poly(density,2) + geno_sex*poly(density,2) , data = glm_2014_data, dist = "negbin") #jday worst in both sides of the model
summary(M2014_HNB4)
```

##### Compare

Let's compare models. First let's use a rootogram.

```{r}
rootogram(M2014_P4, main = "Poisson")
rootogram(M2014_NB4, main = "Negative Binomial")
rootogram(M2014_ZIP4, main = "Zero-Inflated Poisson")
rootogram(M2014_ZINB4, main = "Zero-Inflated Negative Binomial")
rootogram(M2014_HNB4, main = "Hurdle Negative Binomial")
```

Now let's look at a version of qqplots for discrete data. Here we plot randomized quantile residuals against theoretical quantiles.

```{r}
qqrplot(M2014_P4, main = "Poisson")
qqrplot(M2014_NB4, main = "Negative Binomial")
qqrplot(M2014_ZIP4, main = "Zero-Inflated Poisson")
qqrplot(M2014_ZINB4, main = "Zero-Inflated Negative Binomial")
qqrplot(M2014_HNB4, main = "Hurdle Negative Binomial")
```

Now let's look at AIC and BIC
```{r}
AIC(M2014_ZIP4, M2014_ZINB4, M2014_P4, M2014_NB4, M2014_HNB4)
BIC(M2014_ZIP4, M2014_ZINB4, M2014_P4, M2014_NB4, M2014_HNB4)
```

Finally, let's conduct some likelihood ratio tests on nested models. Most of these are already done above, but collecting thme here.

```{r}
lrtest( M2014_ZIP4, M2014_ZINB4 )
lrtest( M2014_P4, M2014_NB4 )
```


__Discussion__  

The rootograms tell us that all models fit the majority of observations (where tlf = 0) quite well. The difference seems to be how well fitness of >0 are fit. Models that do not allow for overdispersion (Poisson and ZIP) are worse than the other models. Negative binomial, hurdle negative binomial and zero-inflated negative bionomial all are roughly equivalent, with the more complex hurdle and zero-inflated negative binomial performing only a little better. The same follows for the qq plots based on randomized residuals. This would suggest we do not need the sophistication and more challenging to interpret zero-inflated/hurdle models, and a "simple" negative binomial glm will suffice.  
The LRTs of nested models tell us that we definitely need to deal with overdispersion.  
When we use AIC or BIC, we also find that the negative binomial is the best model.  

All ways to look at this point the same direction. Use the negative binomial. 

### 2011

```{r}
glm_2011_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

d2011 <- glm_2011_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

glm_2011_data %<>%
  left_join(d2011)

f <- glm_2011_data  %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday) %>% 
  summarise(n_female_rg = n()) 

glm_2011_data  %<>%
  left_join(f)

m <- glm_2011_data  %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday) %>% 
  summarise(n_male_rg = n()) 

glm_2011_data  %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)


select(glm_2011_data, tlf, geno_sex, jday, density, sex_ratio_rg ) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)
```

There are only three release days and one release location in 2011. Since density is calculated per release site, per day, this means we may have strong collinearity. Let's check by fitting a model without interaction (below) and calculating VIFs

```{r}
M2011_NB <- glm.nb(tlf ~ geno_sex   +jday + sex_ratio_rg  , data = glm_2011_data)
M2011_NBa <- glm.nb(tlf ~ geno_sex +density  +jday   , data = glm_2011_data)
M2011_NBb <- glm.nb(tlf ~ geno_sex  +jday  + sex_ratio_rg  , data = glm_2011_data)
summary(M2011_NB)  
summary(M2011_NBa) 
summary(M2011_NBb) 
```

Cannot fit the full model because of the strong collinearity between sex ratio density and date. So fit three models 

```{r}
vif(M2011_NB)
vif(M2011_NBa)
vif(M2011_NBb)
```

No. We can expect reasonable standard errors of the effect estimates for a model that includes all three. Let's choose the most informative by AIC and not forget this when we interpret the results 

```{r}
AIC(M2011_NB, M2011_NBa, M2011_NBb)
```

All fit the data equally well. We'll leave out sex ratio.

First, we'll use a LRT and AIC to examine if it is worth including the non-linear effect of density or jday

```{r}
M2011_NB <- glm.nb(tlf ~ geno_sex  +density  +jday +jday*geno_sex + density*geno_sex , data = glm_2011_data)
M2011_NB2 <- glm.nb(tlf ~ geno_sex  +poly(density,2) + geno_sex*poly(density,2) +jday +jday*geno_sex, data = glm_2011_data)
M2011_NB3 <- glm.nb(tlf ~ geno_sex  +density  +poly(jday,2) +poly(jday,2)*geno_sex + density*geno_sex , data = glm_2011_data)
AIC(M2011_NB, M2011_NB2, M2011_NB3)
anova(M2011_NB, M2011_NB2, M2011_NB3)
#drop1(M2011_NB2, test = "Chisq")
```

No, just use a linear effectf for both

Now we'll do model selection.

```{r}
drop1(M2011_NB, test = "Chisq")
```

Interaction term of sex and density not significant so we'll refit with main effects only
```{r}
M2011_NB5 <- glm.nb(tlf ~ geno_sex  +density + jday+ geno_sex*jday, data = glm_2011_data)
drop1(M2011_NB5, test = "Chisq")
```

Interaction term of sex and jday not significant nowso we'll refit with main effects only

```{r}
M2011_NB6 <- glm.nb(tlf ~ geno_sex  +density + jday, data = glm_2011_data)
drop1(M2011_NB6, test = "Chisq")
```

LRT suggest no significant main effects. Let's go by Wald tests and see what happens.

```{r}
summary(M2011_NB)
summary(update(M2011_NB, .~. - geno_sex*density + geno_sex+density))
summary(update(M2011_NB, .~. - geno_sex*density + geno_sex+density - jday*geno_sex +geno_sex +jday))
summary(update(M2011_NB, .~. - geno_sex*density + geno_sex+density - jday*geno_sex +geno_sex ))
summary(update(M2011_NB, .~. - geno_sex*density + geno_sex - jday*geno_sex +geno_sex ))
summary(update(M2011_NB2, .~. - geno_sex*density + density))
```

No significant effects by LRT or Wald tests. 
__Summary__

In 2011 there were no significant effects. 

### 2012


```{r}
glm_2012_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

d2012 <- glm_2012_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

glm_2012_data %<>%
  left_join(d2012)


f <- glm_2012_data  %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday) %>% 
  summarise(n_female_rg = n()) 

glm_2012_data  %<>%
  left_join(f)

m <- glm_2012_data  %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday) %>% 
  summarise(n_male_rg = n()) 

glm_2012_data  %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)


select(glm_2012_data, tlf, geno_sex, jday, location, density, sex_ratio_rg) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

str(glm_2012_data)
```

As with 2011, we need to simplify our model to avoid collinearity here. There are 2 release sites, but one was used on only a single day. We'll skip location to retain date, because location is so unbalanced.

```{r}
M2012_NB <- glm.nb(tlf ~ geno_sex  +density  +jday  +sex_ratio_rg, data = glm_2012_data)

summary(M2012_NB)  
vif(M2012_NB)
```

Looks good. 

```{r}
M2012_NB <- glm.nb(tlf ~ geno_sex  +density +geno_sex*density +jday+ jday*geno_sex +sex_ratio_rg + sex_ratio_rg*geno_sex  , data = glm_2012_data)

summary(M2012_NB)  
```

Much better. Now let's get to model selection. 

First should we fit either jday or density as non-linear?

```{r}
M2012_NB_nlj <- glm.nb(tlf ~ geno_sex  +density +geno_sex*density +poly(jday,2)+poly(jday,2)*geno_sex + sex_ratio_rg +sex_ratio_rg*geno_sex , data = glm_2012_data)

M2012_NB_nld <- glm.nb(tlf ~ geno_sex  +poly(density,2) +geno_sex*poly(density,2) +jday +jday*geno_sex + sex_ratio_rg +sex_ratio_rg*geno_sex  , data = glm_2012_data)

M2012_NB_nldj <- glm.nb(tlf ~ geno_sex  +poly(density,2) +geno_sex*poly(density,2) +poly(jday,2) +poly(jday,2)*geno_sex + sex_ratio_rg +sex_ratio_rg*geno_sex  , data = glm_2012_data)

AIC(M2012_NB, M2012_NB_nld, M2012_NB_nlj, M2012_NB_nldj)
anova(M2012_NB, M2012_NB_nld, M2012_NB_nlj, test = "Chisq")

```

Fit both as linear. 

Now let's move on to model selection.

```{r}
drop1(M2012_NB, test = "Chisq")
```

Interaction terms not significant,let's refit with main effects and run drop1 again.

```{r}
M2012_NB2 <- glm.nb(tlf ~ geno_sex  +density +jday+ sex_ratio_rg +geno_sex*density + geno_sex*jday , data = glm_2012_data)
drop1(M2012_NB2, test = "Chisq")

M2012_NB3 <- glm.nb(tlf ~ geno_sex  +density +jday+ sex_ratio_rg +geno_sex*density  , data = glm_2012_data)
drop1(M2012_NB3, test = "Chisq")

M2012_NB4 <- glm.nb(tlf ~ geno_sex  +density +jday+ sex_ratio_rg , data = glm_2012_data)
drop1(M2012_NB4, test = "Chisq")
```

LRT suggests no significant effects. Density is almost significant. 

Let's look by Wald.

```{r}
summary(M2012_NB)
summary(glm.nb(tlf ~ geno_sex +sex_ratio_rg +density +jday + jday*geno_sex + geno_sex*density , data = glm_2012_data))
summary(glm.nb(tlf ~ geno_sex +sex_ratio_rg +density +jday + geno_sex*density , data = glm_2012_data))
summary(glm.nb(tlf ~ geno_sex +sex_ratio_rg +density +jday , data = glm_2012_data))
summary(glm.nb(tlf ~ sex_ratio_rg +density +jday , data = glm_2012_data))
summary(glm.nb(tlf ~ sex_ratio_rg +density , data = glm_2012_data))
summary(glm.nb(tlf ~ density , data = glm_2012_data))
M2014_NB_4 <- glm.nb(tlf ~ density , data = glm_2012_data)

```

Wald suggests only density

Now let's examine the fit

```{r}
plot(M2012_NB_4)
qqrplot(M2012_NB_4)
rootogram(M2012_NB_4)
simulateResiduals(M2012_NB_4, plot = TRUE)
```

The fit looks excellent! 

One point of concern was that the single release at Breitenbush had a somewhat high density, so density and location effects could be confounded. The leverage plot above would pick up on any single observations were driving the fit, but since there are many observations from Breitenbush this wouldn't show up. 

Let's summarise the model.

```{r}
M2012_NB_null <- glm.nb(tlf ~ 1  , data = glm_2012_data)
anova(M2012_NB_null, M2012_NB_4)
```

```{r}
summary(M2012_NB_4)
```


__Summary__
The final model fit the better signficantly better than a null model including only an intercept (p= 0.002, LRT). After model selection by testing the impact of individual predictors on fit with LRT and backward stepwise selection using Wald tests, only a single predictor was included in the final model, density. Density had a positive effect on fitness (0.024 +- 0.007, log scale).  

Recalling that location and density are somewhat confounded and we didn't model location, we should also caution that this could be a location effect.


### 2013


```{r}
glm_2013_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

d2013 <- glm_2013_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

glm_2013_data %<>%
  left_join(d2013)


f <- glm_2013_data  %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday) %>% 
  summarise(n_female_rg = n()) 

glm_2013_data  %<>%
  left_join(f)

m <- glm_2013_data  %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday) %>% 
  summarise(n_male_rg = n()) 

glm_2013_data  %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)


select(glm_2013_data, tlf, geno_sex, jday, location, density, sex_ratio_rg) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

str(glm_2013_data)
```

Once again there are systematic relationships between some the variables. Of the three locations, the third was only used at later dates. Only one should remain in the model. We'll choose the most informative by model selection, but need to remember during interpretation that these variables are confounded.


```{r}
M2013_NB <- glm.nb(tlf ~ geno_sex+location  +density  +jday + sex_ratio_rg, data = glm_2013_data)

summary(M2013_NB)  
vif(M2013_NB)
```

First, let's get those VIFs down to something more acceptable. We'll use AIC and LRTs to determine which variable is better to include.

```{r}
M2013_NB2 <- glm.nb(tlf ~ geno_sex  +density +jday +sex_ratio_rg  , data = glm_2013_data)
M2013_NB3 <- glm.nb(tlf ~ geno_sex+location  +density  +sex_ratio_rg  , data = glm_2013_data)
AIC(M2013_NB2, M2013_NB3)
vif(M2013_NB2)
vif(M2013_NB3)
lrtest(M2013_NB2, M2013_NB3)
```

The models without location and without date were equivalently informative, and neither demonstrated further collinearity problems.

Let's fit with location instead of jday, but note that this is somewhat arbitrary and that any effect of location that we find needs to be considered in light of the relationship between these variables. 

Now let's check to see if need to fit a non-linear effect of density before finalizing model selection.

```{r}
M2013_NB4 <- glm.nb(tlf ~ geno_sex+location  +poly(density,2) +geno_sex*poly(density,2)+sex_ratio_rg+sex_ratio_rg*geno_sex  , data = glm_2013_data)
M2013_NB5 <- glm.nb(tlf ~ geno_sex+location  +density +geno_sex*density +sex_ratio_rg+sex_ratio_rg*geno_sex  , data = glm_2013_data)

AIC(M2013_NB4, M2013_NB5)
anova(M2013_NB4, M2013_NB5)
```

Nope a linear effect is sufficient. Moving on to model selection.

First let's use the drop1 command (LRTs for each effect)

```{r}
drop1(M2013_NB5, test = "Chisq")
```

Let's refit without the interaction.
```{r}
drop1((glm.nb(tlf ~ geno_sex+location  +density +geno_sex*density +sex_ratio_rg  , data = glm_2013_data)), test = "Chisq")
drop1((glm.nb(tlf ~ geno_sex+location  +density  +sex_ratio_rg  , data = glm_2013_data)), test = "Chisq")
```

No significant effect by LRT.

Now backward stepwise by Wald

```{r}
summary(M2013_NB5)
summary(glm.nb(tlf ~ geno_sex+location  +density +density*geno_sex +sex_ratio_rg , data = glm_2013_data))
summary(glm.nb(tlf ~ geno_sex+location  +density +sex_ratio_rg , data = glm_2013_data))
summary(glm.nb(tlf ~ geno_sex +density +sex_ratio_rg , data = glm_2013_data))
summary(glm.nb(tlf ~ geno_sex +sex_ratio_rg , data = glm_2013_data))
summary(glm.nb(tlf ~ geno_sex , data = glm_2013_data))

```

No significant effects.

__Summary__ 

No significant effects after model selection in 2013


### 2014


```{r}
glm_2014_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

d2014 <- glm_2014_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

glm_2014_data %<>%
  left_join(d2014)

f <- glm_2014_data  %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday) %>% 
  summarise(n_female_rg = n()) 

glm_2014_data  %<>%
  left_join(f)

m <- glm_2014_data  %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday) %>% 
  summarise(n_male_rg = n()) 

glm_2014_data  %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)


select(glm_2014_data, tlf, geno_sex, jday, location, density, sex_ratio_rg) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

str(glm_2014_data)
```

Once again location and jday are confounded. There is a location that is used very early in the outplanting schedule and then never again. We'll take the same approach as in 2013, and fit whichever variable is most informative in the model, but will need to remember this when interpreting effects.


```{r}
M2014_NB <- glm.nb(tlf ~ geno_sex+location  +density  +jday+ sex_ratio_rg , data = glm_2014_data)

summary(M2014_NB)  
vif(M2014_NB)
```


```{r}
M2014_NBb <- glm.nb(tlf ~ geno_sex +density  +jday+ sex_ratio_rg , data = glm_2014_data)

summary(M2014_NBb)  
vif(M2014_NBb)
```


```{r}
M2014_NB2 <- glm.nb(tlf ~ geno_sex  +density  +jday + geno_sex*density + geno_sex*jday +sex_ratio_rg +sex_ratio_rg*geno_sex, data = glm_2014_data)
M2014_NB3 <- glm.nb(tlf ~ geno_sex+location  +density + geno_sex*density  +sex_ratio_rg +sex_ratio_rg*geno_sex , data = glm_2014_data)
AIC(M2014_NB2, M2014_NB3)
anova(M2014_NB2, M2014_NB3)
```

In this case, dropping location allows for a model that provides a better fit to the data.

Now let's check to see if need to fit a non-linear effect of density before finalizing model selection.

```{r}
M2014_NB4 <- glm.nb(tlf ~ geno_sex  +density  +poly(jday,2) + geno_sex*density + geno_sex*poly(jday,2)+sex_ratio_rg +sex_ratio_rg*geno_sex, data = glm_2014_data)
M2014_NB5 <- glm.nb(tlf ~ geno_sex  +poly(density,2)  +jday + geno_sex*poly(density,2) + geno_sex*jday+sex_ratio_rg +sex_ratio_rg*geno_sex, data = glm_2014_data)
M2014_NB6 <- glm.nb(tlf ~ geno_sex  +poly(density,2)  +poly(jday,2) + geno_sex*poly(density,2) + geno_sex*poly(jday,2)+sex_ratio_rg +sex_ratio_rg*geno_sex, data = glm_2014_data)

AIC(M2014_NB2,M2014_NB4, M2014_NB5, M2014_NB6)
anova(M2014_NB2, M2014_NB4, M2014_NB5, M2014_NB6)
anova(M2014_NB2, M2014_NB5)
```

Fitting density as a quadratic only provides a marginal improvement to the data, will keep linear.

Let's do model selection.

```{r}
drop1(M2014_NB2, test ="Chisq")
```

Let's refit without the insignficant interaction.
```{r}
M2014_NB4 <- glm.nb(tlf ~ geno_sex  +density  +jday + geno_sex*density + geno_sex*sex_ratio_rg , data = glm_2014_data)
drop1(M2014_NB4, test = "Chisq")

M2014_NB4 <- glm.nb(tlf ~ geno_sex  +density  +jday + geno_sex*density  , data = glm_2014_data)
drop1(M2014_NB4, test = "Chisq")
```

LRT suggests a final model with sex, density and their interaction.


```{r}
summary(glm.nb(tlf ~ geno_sex  +density  +jday + geno_sex*density + jday*geno_sex +sex_ratio_rg + sex_ratio_rg*geno_sex  , data = glm_2014_data))

summary(glm.nb(tlf ~ geno_sex  +density  +jday  + jday*geno_sex +sex_ratio_rg + sex_ratio_rg*geno_sex  , data = glm_2014_data))

summary(glm.nb(tlf ~ geno_sex  +density  +jday  + jday*geno_sex +sex_ratio_rg  , data = glm_2014_data))


summary(update(M2014_NB4, .~. -jday))
```

Backward stepwise by Wald agrees. 

Now let's examine the final model fit. 

```{r}
M2014_NB5 <- update(M2014_NB4, .~. -jday)
plot(M2014_NB5)
qqrplot(M2014_NB5)
rootogram(M2014_NB5)
simulateResiduals(M2014_NB5, plot = TRUE)
```

A much better looking fit. For interest, let's see how including the additional covariate and following model selection improved the fit compared to the approach used before.

```{r}
plot(glm_2014_full)
qqrplot(glm_2014_full)
rootogram(glm_2014_full)
simulateResiduals(glm_2014_full, plot = TRUE)
AIC(glm_2014_full, M2014_NB4)
BIC(glm_2014_full, M2014_NB4)
```
Not too different looking in the figures, but a substantial improvement in AIC and BIC

Let's summarise the final model and discuss the results:
```{r}
summary(M2014_NB5)
```

__Summary / discussion__

The final model includes a significant effect of sex, density and their interaction. Males have lower fitness than females overall. Density has a negative effect on fitness for females and a positive effect on males. The overall sex ratio is 292:569, female:male. I plot the estimated effects below (note: should spend more time learning the emmeans package before publishing the figures below!). 

Some things jump out here to discuss later: density effects estimated form individual outplantings suggest that fish s

```{r}
 emmeans::emmip(M2014_NB5,  geno_sex ~ density, cov.reduce = range, type = "scale", CIs = TRUE)+ylab("predicted response in reponse scale \n (tlf, not log(tlf)")+theme_classic()
ggplot(glm_2014_data)+geom_histogram(aes(x = density))+theme_classic()
```

It's easy to see how these models can be used to improve outplanting operations once you start to put these figures together. One thing to explore down the road with mixed modeling and/or comparing paramter estimates across years is whether outplant fitness can be improved through controlling density and sex ratios. This also suggests that sex ratios at individual outplanting events might influence fitness. Perhaps we shold refit models with an additional covariate.  

Let's keep exploring for a bit. 

```{r}
#build release group sex ratio variable
f <- glm_2014_data %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday) %>% 
  summarise(n_female = n()) 

glm_2014_data %<>%
  left_join(f)

m <- glm_2014_data %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday) %>% 
  summarise(n_male = n()) 

glm_2014_data %<>%
  left_join(m) %>%
  mutate(sex_ratio = n_female/n_male)

ggplot(data = glm_2014_data)+geom_histogram(aes(x = sex_ratio))+xlab("n females / n males")

M2014_sr <- glm.nb(tlf ~ sex_ratio + geno_sex + density + sex_ratio*density + density*geno_sex, data = glm_2014_data)
summary(M2014_sr)
drop1(M2014_sr, test = "Chisq")

#interaction of sex ratio and density not significant, fit again
M2014_sr2 <- glm.nb(tlf ~ sex_ratio + geno_sex + density  + density*geno_sex, data = glm_2014_data)
summary(M2014_sr2)
drop1(M2014_sr2, test = "Chisq")

```


### 2015

```{r}
glm_2015_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

d2015 <- glm_2015_data %>%
  group_by(jday, location) %>%
  summarise(density = n())

glm_2015_data %<>%
  left_join(d2015)



f <- glm_2015_data  %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday) %>% 
  summarise(n_female_rg = n()) 

glm_2015_data  %<>%
  left_join(f)

m <- glm_2015_data  %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday) %>% 
  summarise(n_male_rg = n()) 

glm_2015_data  %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)


select(glm_2015_data, tlf, geno_sex, jday, location, density) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

str(glm_2015_data)
```

Once again location and jday are strongly collinear. There is some overlap, but mostly one location is used early and second is used late. Density is also pretty unbalanced with respect to locaiton.

```{r}
M2015_NB <- glm.nb(tlf ~ geno_sex+location  +density  +jday , data = glm_2015_data)
M2015_NB1 <- glm.nb(tlf ~ geno_sex+location  +density  , data = glm_2015_data)

#summary(M2015_NB)  
vif(M2015_NB)
vif(M2015_NB1)
```

```{r}
M2015_NB2 <- glm.nb(tlf ~ geno_sex  +density  +jday + geno_sex*density + geno_sex*jday, data = glm_2015_data)
M2015_NB3 <- glm.nb(tlf ~ geno_sex+location  +density + geno_sex*density   , data = glm_2015_data)

AIC(M2015_NB2, M2015_NB3)

BIC(M2015_NB2, M2015_NB3)
anova(M2015_NB2, M2015_NB3)
```

The model that uses location instead of jday is a little more informative. Will move forward with this one for model selection. 

Let's look for non-linear density effects.
```{r}
M2015_NB4 <- glm.nb(tlf ~ geno_sex+location  +poly(density,2) + geno_sex*poly(density,2)   , data = glm_2015_data)

AIC(M2015_NB3, M2015_NB4)
BIC(M2015_NB3, M2015_NB4)
anova(M2015_NB3, M2015_NB4)

```

Non-linear is slightly better by AIC, worse by BIC, and the LRT suggests the improvement is not significant. Let's use the simpler model (linear)

```{r}
drop1(M2015_NB3, test ="Chisq")
```

Interaction not significant, so let's fit again with main effects

```{r}
M2015_NB5 <- glm.nb(tlf ~ geno_sex+location  +density   , data = glm_2015_data)
drop1(M2015_NB5, test = "Chisq")
```

LRT suggests a final model with sex and location. Now let's do backward stepwise with Wald. 

```{r}
summary(M2015_NB3)
summary(M2015_NB5)
summary(update(M2015_NB5, .~. - density))
```

Stepwise and single term deletions model selections agree: fit a final model with just location and sex.

```{r}
M2015_NB6 <- update(M2015_NB5, .~. - density)
plot(M2015_NB6)
qqrplot(M2015_NB6)
rootogram(M2015_NB6)
simulateResiduals(M2015_NB6, plot = TRUE)
```

__Summary__

Final model included a significant effect of only sex and location. Males had lower fitness than females and Dry Creek had higher fitness than Breitenbush. However, recall that location and release date were strongly collinear. This means the location effect we describe here could also be a release date effect. 

### glm stray thoughts

- density effects are a property of individual outplanting events. one interpration of this is that this suggests the fish from different outplanting evens do not move through the basin and mix much. they tend to spawn with each other. but what about if it has to do with survival until spawning? if so why is there an interaction with sex.

- sex ratios, the density results suggest that we might be interested in sex ratios. shold we examine variation in sex ratios at the level of individual outplanting events, or for the entire year at a time. if the former, then we can do so without mixed models. 


## Mixed Model

Here we explore alternative model specifications for predictors of lifetime fitness.

Compared to the approach taken previously I think we can fit a model that provides more power to predict signficant effects on fitness. I think date should be modeled as a continuous fixed variable (e.g. Julian day), we should add a variable - release group – that should be modeled as a random effect, and all years should be combined into the same model (year included as a second random effect).

I made a note of the rationale here below, in case we want to discuss in the future.

Fitting date as a fixed categorical effect effectively asks if each individual release date is different from others. i.e. did something happen ON THAT DAY that changed the fitness of released fish compared to other days. This may be important to know, but what can this tell us that will allow an improvement to management practices? Simply that some days are better than other. This is an interesting result, but I think we can say more and there is a more interesting way to ask the question. Including the effect of release date as a fixed, continuous variable is more appropriate if we are interested in evaluating the putative effect on fitness of environmental variables that vary over time, but then we are ignoring the batchiness of releases.

There are also day-to-day release batch effects, of course, but these are better fit as random effects because we are more interested in their contribution to variance than their fixed effect per se (e.g. we assume release batch effects are part of population of unsampled batch effects that contribute to variance). A good way to think about this is that if we added infinite years of data, there would be infinitely more levels of these effects, suggesting this is best modeled as a random effect, but eventually we'd saturate the julian day of release variable. As the models are currently specified we do not evaluate the contribution to variance of the batchiness of release day. We just model a linear relationship between julian day and fitness.

A mixed model also allows us to combine years and gain power. By fitting just one model across all years, we increase power to estimate the effects of variables because levels the variables take are repeated across multiple years. (e.g. if releases into the resevoir are somehow reducing fitness, why are we trying to figure this out looking one year at a time, when there are releases there every year). Here we are not interested in year over year trends in fitness or the contributions of specific years to fitness as much as we are interested in the variation due to year and evaluating the effects of release date, sex and release location after accounting for annual variation. This suggests we should fit year as a random effect. Fitting year as a fixed effect asks a different question and perhaps we should evaluate this as well.

Year level fixed effects are also likely to have a large influence on fitness. However, there are many unmeasured variables that vary across years. From the available data, the annual level variables with the most biologically interpretable hypothetical effects are number of outplants and sex ratios.

Finally, I don't think there's any good reason to assume a linear relationship between Julian day or the number of fish released (density) and fitness. We should expect stabilizing selection, suggesting that we should evaluate a quadratic effect of Julian day and/or density (after scaling and centering) on fitness. 

### Mixed Modeling Overview

We primarily follow the approach described in Zuur et al 2009. Mixed Effects Models and Extensions in Ecology with R.

(1) __Exploratory Data Analysis:__ First we explore the relationships between all variables in the dataset.  
(2) __Multicollinearity:__  In addition to our findings from EDA above, we fit main effects models calculate variance inflation factors to identify multicollinearity among main effects.  
(3) __Random Effects Model Selection:__ After removing effects contributing to multicollinearity in a main effects only model, we fit an otherwise saturated models including all main effects and interactions, but varied which random effects were included. Model fit was by REML. We chose the best random effects structure by AIC and LRTs.  
(4) __Fixed Effects Model Selection:__ We conducted model selection on the fixed effects using LRTs and backward stepwise selection on Wald tests for signficant effects (p < 0.05 not multiple comparison corrected). Model fit was by ML. For the LRTs we stepwise dropped non-significant interaction terms from the model, to evaluate if main effects were significant.  
(5) __Model Validation:__ We validated the model using simulated residuals from the DHARMa package.  
(6) __Estimated Marginal Means and Effect:__ To improve biological intepretation of signficant predictors of fitness, we estimated marginal means for significant effects.  

### Data and EDA

Let's prepare the data. We need several additional variables (release group, julian day, density for each release group, total number of fish released in a year).

```{r}
mm_data <-  parents %>%
  filter(type %in% c("outplant", "reintro_above"), year <2016) %>%
  select(date, geno_sex, location, tlf, year) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>% #julian day in this case: days since the first day of the year
  mutate(jday_c = scale(jday, scale = F),#center the julian day to help with convergence
         geno_sex = as.factor(geno_sex),
         location = as.factor(location),
         year = as.factor(year),
         group = as.factor(paste(date, location)))

# lets add density
dens <- mm_data %>%
 group_by(jday, location, year) %>%
  summarise(density = n())

mm_data %<>%
  left_join(dens)

# lets add overall size of release in a year
dens <- mm_data %>%
 group_by( year) %>%
  summarise(annual_n = n())

mm_data %<>%
  left_join(dens)


# lets add sex ratio
#build release group sex ratio variable
f <- mm_data %>% 
  filter(geno_sex == "F") %>%
  group_by(location, jday, year) %>% 
  summarise(n_female_rg = n()) 

mm_data %<>%
  left_join(f)

m <- mm_data %>% 
  filter(geno_sex == "M") %>%
  group_by(location, jday, year) %>% 
  summarise(n_male_rg = n()) 

mm_data %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)

# maybe the release groups all mix thoroughly spawn together and we should fit sex ratio at the level of year
f <- mm_data %>% 
  filter(geno_sex == "F") %>%
  group_by( year) %>% 
  summarise(n_female_y = n()) 

mm_data %<>%
  left_join(f)

m <- mm_data %>% 
  filter(geno_sex == "M") %>%
  group_by( year) %>% 
  summarise(n_male_y = n()) 

mm_data %<>%
  left_join(m) %>%
  mutate(sex_ratio_y = n_male_y/n_female_y)


mm_data %<>%
  mutate(sex_ratio_rg_l = log(sex_ratio_rg),
         sex_ratio_y_l = log(sex_ratio_y))

mm_data %<>%
  drop_na()

```

Let's explore the data a bit too and look for issues with collinearity

```{r}
select(mm_data, tlf, geno_sex, jday, density,sex_ratio_y_l, sex_ratio_rg_l, annual_n , location) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

beyond_opt_main <- glm.nb(tlf ~ jday_c + geno_sex + location  + density+sex_ratio_y_l + sex_ratio_rg_l + annual_n, data = mm_data)
vif(beyond_opt_main)
```

Location demonstrates strong multicollinearity . This isn't surprising given our analyses within years. Let's remove and look ant VIFs again.


```{r}
beyond_opt_main <- glm.nb(tlf ~ jday_c + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l + annual_n, data = mm_data)
vif(beyond_opt_main)
```

Now annual sex ratio seems to present the biggest problem, probably due to it's relationship with the other annual level variable: annual_n.

Let's choose which to keep by AIC. We'll fit each model with all other possible fixed and random effects and compare.

```{r}
no_loc_1 <- glmmTMB(tlf ~ jday_c + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l + annual_n +geno_sex*jday_c + geno_sex*density + geno_sex*sex_ratio_y_l + geno_sex*sex_ratio_rg_l + (1|group) + (1|year) , data = mm_data, family = nbinom2) #both

no_loc_2 <- glmmTMB(tlf ~ jday_c + geno_sex + density + sex_ratio_rg_l  +geno_sex*jday_c + geno_sex*density  + geno_sex*sex_ratio_rg_l  + (1|group) + (1|year) , data = mm_data, family = nbinom2) #no annual sex ratio 

no_loc_3 <- glmmTMB(tlf ~ jday_c + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l  +geno_sex*jday_c + geno_sex*density + geno_sex*sex_ratio_y_l + geno_sex*sex_ratio_rg_l  + (1|group) + (1|year) , data = mm_data, family = nbinom2) #no annual n


AIC(no_loc_1, no_loc_2, no_loc_3)
lrtest(no_loc_1, no_loc_3)
lrtest(no_loc_1, no_loc_2)
lrtest(no_loc_2, no_loc_3)

```

Including annual sex ratios is a much better fit to the data than annual outplanting program size. The best fit includes only annual sex ratio, but it's not a very big jump in AIC. Let's keep both.

```{r}
beyond_opt_main_x <- glm.nb(tlf ~ jday_c + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l + annual_n, data = mm_data)
vif(beyond_opt_main_x)
```

As a summary so far: location demonstrated collinearity with release date in some years. Any significant effect of release date needs to be considered in light of this confounding. We also considered two year-level fixed effects, total number of outplants in a year and the overall sex ratio among outplants in a year. These were only slightly collinear, but we should remember that any year level effects are confounded by all the other variables, considered here or otherwise, that vary between years and could be driving signifcant effects.

### Model Selection

Now lets fit the beyond optimal model. This has more fixed effects than we could possibly want in our final model, but that is desirable for finding the optimum random effect structure.

```{r, cache = TRUE, eval = FALSE}
mm_beyond_opt <- glmmTMB(tlf ~ jday_c + geno_sex  +  density+ annual_n + geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2, REML = TRUE)

mm_beyond_opt2 <- glmmTMB(tlf ~ jday_c + geno_sex +  density+ annual_n+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l  +(1|year), data = mm_data, family = nbinom2,  REML = TRUE)

mm_beyond_opt3 <- glmmTMB(tlf ~ jday_c + geno_sex +  density + annual_n+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l +   (1|group), data = mm_data, family = nbinom2,  REML = TRUE)

mm_beyond_opt4 <- glmmTMB(tlf ~ jday_c + geno_sex +  geno_sex* density + annual_n+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l , data = mm_data, family = nbinom2,  REML = TRUE)



AIC(mm_beyond_opt, mm_beyond_opt2, mm_beyond_opt3, mm_beyond_opt4)
BIC(mm_beyond_opt, mm_beyond_opt2, mm_beyond_opt3, mm_beyond_opt4)

lrtest(mm_beyond_opt4, mm_beyond_opt)
lrtest(mm_beyond_opt4, mm_beyond_opt2)
lrtest(mm_beyond_opt4, mm_beyond_opt3)

summary(mm_beyond_opt)
```

AIC and BIC agree the best fit to the data is the full random effects model including both release group and year. 

Let's refit the model using ML.

```{r}
mm_beyond_opt <- glmmTMB(tlf ~ jday_c + geno_sex  +  density+ annual_n + +sex_ratio_y_l + sex_ratio_rg_l + geno_sex*density + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

summary(mm_beyond_opt)
```




Now that we have the random structure figured out, let's do model selection on the fixed effects.

First should we fit density and/or jday as non-linear

```{r}
beyond_opt_nl2 <- glmmTMB(tlf ~ poly(jday_c,2) + geno_sex  +  poly(density,2) + annual_n + sex_ratio_y_l + sex_ratio_rg_l + geno_sex*poly(density,2) + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

beyond_opt_nld <-glmmTMB(tlf ~ jday_c + geno_sex  +  poly(density,2) + annual_n + sex_ratio_y_l + sex_ratio_rg_l + geno_sex*poly(density,2) + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

beyond_opt_nlj <- glmmTMB(tlf ~ poly(jday_c,2) + geno_sex  +  density + annual_n + sex_ratio_y_l + sex_ratio_rg_l + geno_sex*density + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)
  
  
AIC(beyond_opt_nlj, beyond_opt_nl2, beyond_opt_nld, mm_beyond_opt3)
BIC(beyond_opt_nlj, beyond_opt_nl2, beyond_opt_nld, mm_beyond_opt3)
```

Linear effects are a much worse fit to the data than quadratics for density, release date or both. According to AIC a model with both fit as quadratic is optimal. According to BIC a model with only day is optimal. There's good a priori biological reason to assume both should be non-linear, so my decision making framework here is that we should only keep the sparse model (linear) if there is strong evidence in its favor. Let's fit both as non-linear.


```{r}
drop1(beyond_opt_nl2, test = "Chisq")
```

Let's get rid of the worst interaction term and fit again


```{r}
drop1(update(beyond_opt_nl2, . ~ . - geno_sex*sex_ratio_rg_l + sex_ratio_rg_l), test = "Chisq")
```

Still some non-significant interactions.


```{r}
drop1(glmmTMB(tlf ~ poly(jday_c,2) + geno_sex  +  poly(density,2) + annual_n + sex_ratio_y_l + sex_ratio_rg_l  + geno_sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2), test = "Chisq")
```

LRT suggests only sex, annual sex ratio and their interaction are signficant. Now Let's do backward stepwise using Wald Tests.



__old code__
```{r, eval = FALSE}
drop1(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l, data = mm_data), test = "Chisq")
```

Still more

```{r}
drop1(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_y_l, data = mm_data), test = "Chisq")
```


Still more

```{r}
drop1(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_y_l, data = mm_data), test = "Chisq")
```

```{r}
drop1(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l, data = mm_data), test = "Chisq")
```

__wald__

Final model by LRT (including backward stepwise elimination of non-significant interaction effects) includes on main effects of day, sex, and annual sex ratio.

Now let's do backward stepwise selection by wald tests. 

```{r}
summary(glmmTMB(tlf ~ jday_c + geno_sex  + geno_sex + density+ sex_ratio_y_l + sex_ratio_rg_l + geno_sex*density +  geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + density*sex_ratio_y_l + density*sex_ratio_rg_l + (1|group), family = nbinom2, data =mm_data))
```



```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + density*sex_ratio_y_l + density*sex_ratio_rg_l, data = mm_data))
```
```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l + density*sex_ratio_rg_l, data = mm_data))
```

```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+ geno_sex*density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l, data = mm_data))
```


```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_rg_l + geno_sex*sex_ratio_y_l, data = mm_data))
```


```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l + geno_sex*sex_ratio_y_l, data = mm_data))
```



```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+sex_ratio_y_l + sex_ratio_rg_l,  data = mm_data))
```


```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex + density+sex_ratio_y_l ,  data = mm_data))
```


```{r}
summary(glm.nb(tlf ~ jday_c + geno_sex  + geno_sex +sex_ratio_y_l ,  data = mm_data))
```

Final model by backward stepwsie selection on the Wald test finds the same model.

### Model validation


```{r}
final_model <- glmmTMB(tlf ~  geno_sex  +sex_ratio_y_l + geno_sex*sex_ratio_y_l + (1|group) +  (1|year),  data = mm_data, family = nbinom2)
#plot(final_model)
#qqrplot(final_model)
#rootogram(final_model)
simulateResiduals(final_model, plot = TRUE)
```



Model fits excellently!


### Effects

```{r}
summary(final_model)
```


__Sex__

Males have lower fitness than females, but the main effect is not significant, instead it is the interaction with sex ratio that seems to drive the difference

Below we plot estimated marginal means. 
```{r}
require(emmeans)
sex_effect <- emmeans(final_model, specs = pairwise ~ geno_sex, type = "response" )
sex_effect
plot(sex_effect)+theme_classic()+xlab("Estimated Marginal Mean TLF\nwith 95% CIs")+ylab("sex")
```

```{r}
ggplot(data = mm_data)+geom_boxplot(aes(x = geno_sex, y = log(tlf)))
```


__Sex Ratio__

As the sex ratio is biased towards more males, overall fitness is decreased. Still working on estimated marginal means, instead I plot the predictions from the model and the actual data. 

```{r}
ggplot(data = mm_data, aes(y = log(tlf), x =exp(sex_ratio_y_l)))+geom_jitter( alpha = 0.5)+stat_summary(
    geom = "point",
    fun.y = "mean",
    col = "black",
    size = 3,
    shape = 24,
    fill = "red"
  )+theme_classic()+xlab("Annual Sex Ratio\n(male/female)")+ylab("Log(TLF)")+ggtitle("Log Total Lifetime Fitness vs Annual Sex Ratios\nActual Data")

ggplot(data = mm_data, aes(y = (tlf), x =exp(sex_ratio_y_l)))+geom_jitter( alpha = 0.5)+stat_summary(
    geom = "point",
    fun.y = "mean",
    col = "black",
    size = 3,
    shape = 24,
    fill = "red"
  )+theme_classic()+xlab("Annual Sex Ratio\n(male/female)")+ylab("(TLF)")+ggtitle("Total Lifetime Fitness vs Annual Sex Ratios\nActual Data")
```

```{r}
pred1 <- as.data.frame( cbind(exp(mm_data$sex_ratio_y_l),predict(final_model, type = "response", terms = "sex_ratio_y_l")))
colnames(pred1) <- c("sex_ratio_y_l", "predicted_tlf")


ggplot(data = pred1)+geom_point(aes(sex_ratio_y_l,predicted_tlf))+ theme_classic()+xlab("Annual Sex Ratio\n(male/female)")+ylab("Predicted  TLF)")+ggtitle("Total Lifetime Fitness vs Annual Sex Ratios\nModel Predictions")
```

Fairly large effect of sex ratio. 

__Interaction__

The effect of sex overall is not significant, it is only it's interaction with sex ratio that drives differences between fitness. Below we plot some interaction plots. 

```{r}
emmip(final_model, geno_sex ~ sex_ratio_y_l, cov.reduce = range, type = "response")+theme_classic()+scale_color_viridis_d(end = 0.8)+xlab("Sex Ratio\n Log(N Males / NFemales)")+ylab("Predicted Fitness")

emmip(final_model, geno_sex ~ sex_ratio_y_l, cov.keep = "percent", type = "response", at = list(sex_ratio_y_l = c(-0.3, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7)))+theme_classic()+scale_color_viridis_d(end = 0.8)+xlab("Sex Ratio\n Log(N Males / NFemales)")+ylab("Predicted Fitness")

emmip(final_model, geno_sex ~ sex_ratio_y_l, cov.keep = "percent", type = "response", at = list(sex_ratio_y_l = c(-0.3, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7)), CIs = TRUE)+theme_classic()+scale_color_viridis_d(end = 0.8)+xlab("Sex Ratio\n Log(N Males / NFemales)")+ylab("Predicted Fitness")
```











### other



Global model is significant. Let's look at the quality of the fit.

```{r, eval = FALSE}
simulateResiduals(mm_full, plot = TRUE)
```

There's some issues with the full model:  

Group random effect doesn't seem to be doing much. The variance driven by group is only about 1/70th of the variance driven by year. We will probably benefit from removing this variance term from the final model.  
The magnitude of the standardized residuals doesn't depend on the fitted values, which is good, but we see that the residuals themselves are quite large, indicating that it is not a very powerful model. 

Let's see if we can specify a better model.  

### Model Selection

We will follow the approach from Zuur et al 2009: First find the optimum random structure by including the fully saturated fixed model, but varying the random effects. Choose by AIC. Then fit all possible fixed effect structures with this "best" random effect structure. Choose best here by AIC as well. 

First the random effects:
```{r, cache = TRUE, eval = FALSE}
mm_linear <- glm.nb(tlf ~ jday_c + geno_sex + location + geno_sex*location, data = mm_data) 
mm_ran_1 <- glmer.nb(tlf ~ jday_c + geno_sex + location + geno_sex*location+ (1|group), data = mm_data) 
mm_ran_2 <- glmer.nb(tlf ~ jday_c + geno_sex + location + geno_sex*location+ (1|year), data = mm_data) 
#mm_full <- glmer.nb(tlf ~ jday_c + geno_sex + location + geno_sex*location+ (1|group) + (1|year), data = mm_data) 

```

```{r, eval = FALSE}
AIC(mm_linear, mm_ran_1, mm_ran_2, mm_full)
```

The full random model and the random model with only year as random effect were within 2 AIC. This suggests they are equivalent and we should choose the one with the fewest parameters. So our final random effect structure is just year.

Now that we the optimum random effect structure, let's find the fixed effect structure:

```{r, eval = FALSE}
# 3 effects
mm_f1 <- glmer.nb(tlf ~ jday_c + geno_sex + location + (1|year), data = mm_data) 
mm_f2 <- glmer.nb(tlf ~ jday_c + geno_sex +  geno_sex*location+ (1|year), data = mm_data) 
mm_f3 <- glmer.nb(tlf ~ jday_c  + location + geno_sex*location+ (1|year), data = mm_data) 
mm_f4 <- glmer.nb(tlf ~ geno_sex + location + geno_sex*location+ (1|year), data = mm_data) 

# 2 effects
mm_f5 <- glmer.nb(tlf ~ jday_c + geno_sex + (1|year), data = mm_data) 
mm_f6 <- glmer.nb(tlf ~ jday_c + location + (1|year), data = mm_data) 
mm_f7 <- glmer.nb(tlf ~ jday_c + geno_sex*location + (1|year), data = mm_data) 
mm_f8 <- glmer.nb(tlf ~ geno_sex + location + (1|year), data = mm_data) 
mm_f9 <- glmer.nb(tlf ~ geno_sex + geno_sex*location + (1|year), data = mm_data) 
mm_f10 <- glmer.nb(tlf ~ location + geno_sex*location + (1|year), data = mm_data) 

# 1 effects
mm_f11 <- glmer.nb(tlf ~ jday_c + (1|year), data = mm_data) 
mm_f12 <- glmer.nb(tlf ~ geno_sex + (1|year), data = mm_data) 
mm_f13 <- glmer.nb(tlf ~ location + (1|year), data = mm_data) 
mm_f14 <- glmer.nb(tlf ~ geno_sex*location + (1|year), data = mm_data) 

AIC(mm_f1, mm_f2, mm_f3, mm_f4, mm_f5, mm_f6, mm_f7, mm_f8, mm_f9, mm_f10, mm_f11, mm_f12, mm_f13, mm_f14)
```


### Final Model

The final model includes 2 fixed (sex and julian day) and one random effect (year). Results from thsi model are below.

First let's get the likelihood ratios, df, and p-values (from chi-square test) for each effect 
```{r, eval = FALSE}
kable(anova(mm_f12, mm_f5), caption = "LRT for Julian Day", align = "c") %>% # jday
  kable_classic(full_width = F, html_font = "Cambria")
  
kable(anova(mm_f11, mm_f5), caption = "LRT for Sex", align = "c") %>% # jday
  kable_classic(full_width = F, html_font = "Cambria")  
  
```

let's stop until I can get better at mixed modeling. some resources to read

Zuur book 1 
Zuur book 2 (should we consider zero inflation) Zuur, A. F. S., A. A. Ieno. 2012. Zero inflated models and generalized linear mixed models with R.
Bolker faq: bbolker.github.io/mixedmodels-misc
Bolker, B. M., M. E. Brooks, C. J. Clark, S. W. Geange, J. R. Poulsen, M. H. H. Stevens, and J.-S. S. White. 2009. Generalized linear mixed models: a practical guide for ecology and evolution. Trends in Ecology & Evolution 24:127–135.


# Effective Number of Breeders

Calculated Nb using LD method from NeEstimator v2.1. Used GUI, so only logging the parameters used here, not calculating the values.

Parameters:  
MAF: 0.02  
CIs: 95% confidence intervals from jacknife re-sampling method  
Data: Data for a given year is the assigned offspring of that year  

## Data Prep
### Outplants

#### 2011 

Let's create the input data for NeEstimator. We'll take advantage of a wrapper function from adegenet to output a genepop file all assigned offspring for each parent year.

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2011 <- pedigree_meta %>%
  filter(mother_year == 2011 | father_year ==2011) %>%
  filter(mother_type  == "outplant" | father_type == "outplant") %>%
  pull(offspring_sample_id)

gts_off_of_2011 <- full_meta %>%
  filter(sample_id %in% offspring_of_2011) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2011 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2011 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2011[,3:ncol(gts_off_of_2011)],pops = gts_off_of_2011$pop,ind.ids = gts_off_of_2011$sample_id,folder = "neestimator/outplants/",filename ="genepop_2011.txt",ncode = 3,diploid = T)


```

Neestimator results are not formatted to be easily parsed by machine. Instead, wrote results manually to a spreadsheet. We'll import it in the end.

#### 2012

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2012 <- pedigree_meta %>%
  filter(mother_year == 2012 | father_year ==2012) %>%
  filter(mother_type  == "outplant" | father_type == "outplant") %>%
  pull(offspring_sample_id)

gts_off_of_2012 <- full_meta %>%
  filter(sample_id %in% offspring_of_2012) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2012 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2012 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2012[,3:ncol(gts_off_of_2012)],pops = gts_off_of_2012$pop,ind.ids = gts_off_of_2012$sample_id,folder = "neestimator/outplants/",filename ="genepop_2012.txt",ncode = 3,diploid = T)


```

#### 2013

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2013 <- pedigree_meta %>%
  filter(mother_year == 2013 | father_year ==2013) %>%
  filter(mother_type  == "outplant" | father_type == "outplant") %>%
  pull(offspring_sample_id)

gts_off_of_2013 <- full_meta %>%
  filter(sample_id %in% offspring_of_2013) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2013 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2013 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2013[,3:ncol(gts_off_of_2013)],pops = gts_off_of_2013$pop,ind.ids = gts_off_of_2013$sample_id,folder = "neestimator/outplants/",filename ="genepop_2013.txt",ncode = 3,diploid = T)


```

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2014 <- pedigree_meta %>%
  filter(mother_year == 2014 | father_year ==2014) %>%
  filter(mother_type  == "outplant" | father_type == "outplant") %>%
  pull(offspring_sample_id)

gts_off_of_2014 <- full_meta %>%
  filter(sample_id %in% offspring_of_2014) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2014 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2014 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2014[,3:ncol(gts_off_of_2014)],pops = gts_off_of_2014$pop,ind.ids = gts_off_of_2014$sample_id,folder = "neestimator/outplants/",filename ="genepop_2014.txt",ncode = 3,diploid = T)


```

#### 2015

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2015 <- pedigree_meta %>%
  filter(mother_year == 2015 | father_year ==2015) %>%
  filter(mother_type  == "outplant" | father_type == "outplant") %>%
  pull(offspring_sample_id)

gts_off_of_2015 <- full_meta %>%
  filter(sample_id %in% offspring_of_2015) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2015 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2015 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2015[,3:ncol(gts_off_of_2015)],pops = gts_off_of_2015$pop,ind.ids = gts_off_of_2015$sample_id,folder = "neestimator/outplants/",filename ="genepop_2015.txt",ncode = 3,diploid = T)


```

### Reintros

#### Reintro Above (2015)

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2015 <- pedigree_meta %>%
  filter(mother_year == 2015 | father_year ==2015) %>%
  filter(mother_type  == "reintro_above" | father_type == "reintro_above") %>%
  pull(offspring_sample_id)

gts_off_of_2015 <- full_meta %>%
  filter(sample_id %in% offspring_of_2015) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2015 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2015 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2015[,3:ncol(gts_off_of_2015)],pops = gts_off_of_2015$pop,ind.ids = gts_off_of_2015$sample_id,folder = "neestimator/reintros/",filename ="genepop_2015_above.txt",ncode = 3,diploid = T)


```

#### Reintro Below (2013)

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2013 <- pedigree_meta %>%
  filter(mother_year == 2013 | father_year ==2013) %>%
  filter(mother_type  == "reintro" | father_type == "reintro") %>%
  pull(offspring_sample_id)

gts_off_of_2013 <- full_meta %>%
  filter(sample_id %in% offspring_of_2013) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2013 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2013 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2013[,3:ncol(gts_off_of_2013)],pops = gts_off_of_2013$pop,ind.ids = gts_off_of_2013$sample_id,folder = "neestimator/reintros/",filename ="genepop_2013.txt",ncode = 3,diploid = T)


```


#### Reintro Below (2014)

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2014 <- pedigree_meta %>%
  filter(mother_year == 2014 | father_year ==2014) %>%
  filter(mother_type  == "reintro" | father_type == "reintro") %>%
  pull(offspring_sample_id)

gts_off_of_2014 <- full_meta %>%
  filter(sample_id %in% offspring_of_2014) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2014 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2014 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2014[,3:ncol(gts_off_of_2014)],pops = gts_off_of_2014$pop,ind.ids = gts_off_of_2014$sample_id,folder = "neestimator/reintros/",filename ="genepop_2014.txt",ncode = 3,diploid = T)


```

#### Reintro Below (2015)

```{r, message=FALSE, warning=FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2015 <- pedigree_meta %>%
  filter(mother_year == 2015 | father_year ==2015) %>%
  filter(mother_type  == "reintro" | father_type == "reintro") %>%
  pull(offspring_sample_id)

gts_off_of_2015 <- full_meta %>%
  filter(sample_id %in% offspring_of_2015) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2015 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2015 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2015[,3:ncol(gts_off_of_2015)],pops = gts_off_of_2015$pop,ind.ids = gts_off_of_2015$sample_id,folder = "neestimator/reintros/",filename ="genepop_2015.txt",ncode = 3,diploid = T)


```

## Results

```{r, message=FALSE}
nb <- readxl::read_xlsx("neestimator/Nb_results.xlsx", sheet = 1)


#let's add the counts of number of candidate parents, number of successful parents estimated from the pedigree

#get counts total candidates

nb <- meta_data %>%
  mutate(year = as.numeric(year)) %>%
  count(year, type) %>%
  right_join(nb) %>%
  rename(n_candidate_parents = n)

# get basic counts of successful parents (candidate parents in row with at least one offspring)

# kable(pedigree_meta %>%
#   mutate(parent_year = coalesce(mother_year, father_year)) %>%
#   select( parent_year, father_id = father, mother_id = mother, father_type, mother_type) %>%
#   pivot_longer(cols = c(father_id, father_type, mother_id, mother_type), names_to = c("parent_sex", ".value"), names_sep = "_") %>%
#   filter(id != "none") %>%
#   distinct(id, .keep_all = TRUE) %>%
#   count(parent_year, type), align = "c", caption = "number of parents with at least one assigned offspring, parents considered individually") %>%
#   kable_classic(full_width = F, html_font = "Cambria")

#also add these results to the results table
nb <- pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  select( parent_year, father_id = father, mother_id = mother, father_type, mother_type) %>%
  pivot_longer(cols = c(father_id, father_type, mother_id, mother_type), names_to = c("parent_sex", ".value"), names_sep = "_") %>%
  filter(id != "none") %>%
  distinct(id, .keep_all = TRUE) %>%
  count(parent_year, type) %>%
  rename(year = parent_year) %>%
  mutate(year = as.numeric(year)) %>%
  right_join(nb) %>%
  rename(n_successful_parents = n)

  

# now present nb

nb %<>%
  mutate(nb_n_ratio = Nb/n_successful_parents) %>%
  relocate(year, type, Nb, ci_lower, ci_higher)

kable(nb, align = "c", caption = "Nb results table") %>% kable_classic(full_width = F, html_font = "Cambria") %>%
  footnote(number = c("n_succesful_parents: number of parents with at least one offspring in the final pedigree", "n_candidate_parents: total number of parents included as candidates in the pedigree analysis", "nb_n_ratio: (estimated Nb)/(n_successful_parents)"))
```


## Discussion

These are some stray thoughts I have, don't feel the need to dive into the weeds here if pressed for time.



__Issues__  
Note that there are two issues that are a little confusing here and may warrant resolving:  

_Which Cohorts: Outplant and Reintros OR Above and Below?_   
We include all offspring that have at least one assigned offspring to a parent cohort as part of that parent cohort's dataset used to estimate Nb. There are two parent cohorts under consideration in the analysis: reintros, and outplants (3 if you also include rentros above Detroit). However there are only two biological parent cohorts, above Detroit and below Big Cliff. Carcass samples appear in the pedigree as parents with both outplants (above) and reintros (below), so they can be part of either cohort, either because the carcass was sampled above the dam (n = 15) or because the carcass was sampled below the dam (n = 427), and spawned below the dam, or spawned above the dam but passed over/through the dam after spawning.  
As a consequence, our understanding of the census size of successful spawners in a cohort (as estimated by the number of parents in a given year/group with assigned offspring) is biased downwards, because any carcass samples from fish that spawned successfully as a member of this cohort are not counted.
Since we can't say for sure if a carcass was part of the above or below dam cohort unless it's spawning partner is assigned (e.g it is part of a parent-offspring trio with a non-carcass sample parent), we can't simply add all carcass parentages to the total. However, we can count a carcass sample as part of the above or below dam cohort if it is a member of a trio. In the results below I present both numbers, we can choose which to include in the report down the road.

_Single Parents_  
A second way to improve our count of prents in a cohort would be to infer a second parent for single parent matches. If a offspring is assigned to a single parent, we can assume there was a second parent and the assignment was not made because (i) the parent was not included in our set of candidate parents because it was not sampled, (ii) the parent was sampled, but not included in our set of candidate parents because ithad insufficient data to be included, or (iii) the second parent was in the datset but incorrectly excluded due to assignment criteria. 

In the case of (i) or (ii) we could simply add a second parent to the counts and imporve our estimate of the number of parents in a cohort. However the possibility of (iii) presents a problem. We might double count an individual, if it is excluded from some parentages, but not others. Also, we may over estimate the number of parents if an inferred excluded parent contributed to multiple parentages. I do not attempt to infer the number of parents accounting for single parentage because of these multiple issues.

_Nb bigger than N_successful / synthesis of issues above_  

Throughout the Nb results and discussion in the text we consider why Nb is sometimes larger or similar to the number of parents that produced at least one offspring in the pedigree. It should probably always be lower, substantially so given the variance year to year in population size, skewed sex ratios and other things going on. So what's going on here?

Let's ignore the single parent issue for now.  


```{r}

# get counts of different types of parent pairs
kable(pedigree_meta %>%
  mutate(parent_year = coalesce(mother_year, father_year)) %>%
  select(parent_type, parent_year, father, mother) %>%
  pivot_longer(cols = c(father, mother), names_to = "parent_sex", values_to = "parent_id" ) %>%
  filter(parent_id != "none") %>%
  distinct(parent_id, .keep_all = TRUE) %>% 
  count(parent_year, parent_type), align = "c", caption = "number of parents with at least one assigned offspring, types for both parents presented if trio, see note about error in this table") %>%
  kable_classic(full_width = F, html_font = "Cambria")

# note there's a problem with this table, we filter duplicates, so when a single individual has spawning partners of multiple types, the count by type is only counted once. For example, a 2015 outplant individual that spawns with both other outplants and reintros is either included in the outplants total or the outplant/reintro total depdending on which is the first (by row order) in the pedigree dataframe. Figuring out the right way to add these up will take some time, so skipping for now unless we really want to include these numbers in the report.
```

Consider the table above, it suggests which number to present as the number of parents from the pedigree is not straightforward. In the n_successful parents column in the Nb results table we consider each parent individually, in the table above we consider parent types for both parents in a trio, which is the more informative value to present, because it tells us about the actual cohort of individuals that spawned together. For example, for the 2011 outplant parent cohort, should the number be 51 to reflect only outplants, or 52 to reflect that we know that one carcass individual produced offspring in the pedigree with one outplants? 

Now that we've established this, let's discuss why in some groups (all reintro below), the estimated Nb is greater than the number of successful parents in the pedigree. 

__Negative assortative mating?__  
Maybe, but doubtful.   

__Our assignment criteria are too stringent given the amount of mis-genotypting and undersampling of candidate parents?__  
This might be the case, but we can't do much about this right now. If true, it is a bit troubling that the problem is more severe in one parent type (reintros below) than others.

__The cohort is artificially small because we split by type rather than spawning location?__   
__YES__, we can positively assess this. In 2015, there are at least 151 parents above the dam that spawned with a different type than themselve (e.g. reintro above/outplant). To accurately reflect the number of parents in the above dam cohort with at least a single offspring in the pedigree we need to use the table above. Including all parents we know to contribute above the dam (including carcasses) the inferred number of succesful parents should be 478 (reintros above + outplants + carcasses known to have spawned above the dam). I do some extra work to explore this in the section "2015 Combined" below. 



__Note__ there's a problem with the second table. We filter duplicate parents from the pedigree to get the counts (i.e. count each successful parent once, not once per each offspring it produces), so when a single individual parent has spawning partners of multiple types, the count by type is only counted once. For example, a 2015 outplant individual that spawns with both other outplants and reintros is either included in the outplants total or the outplant/reintro total depdending on which is the first (by row order) in the pedigree dataframe. Figuring out the right way to add these up will take some time, in the interest of time I'm not going to fix this problem, unless we really want to include these numbers in the report. For now, we should just be aware that the counts in the second table are MINIMUMS, not the actual number, but they highlight the question about what is the best way to think about cohort size: by parent type, or by above/below the dams


### 2015 Combined

To further explore the issues described above. I also ran NeEstimator for all parents above Detroit in 2015 (excluding carcasses sampled below the dam, but assigned to have spawned with a second parent above the dam). 


```{r, message=FALSE, warning = FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohor
offspring_of_2015 <- pedigree_meta %>%
  filter(mother_year == 2015 | father_year ==2015) %>%
  filter(mother_type  == "reintro_above" | father_type == "reintro_above" | mother_type == "outplant" | father_type == "outplant" | mother_type == "carcass_above" | father_type == "carcass_above") %>%
  pull(offspring_sample_id)

gts_off_of_2015 <- full_meta %>%
  filter(sample_id %in% offspring_of_2015) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2015 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2015 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_off_of_2015[,3:ncol(gts_off_of_2015)],pops = gts_off_of_2015$pop,ind.ids = gts_off_of_2015$sample_id,folder = "neestimator/2015_above/",filename ="genepop_2015.txt",ncode = 3,diploid = T)


```

For the 2015 above Detroit parent cohort (ignoring carcasses to be consistent with the table as presented earlier), the number of offspring in the dataset was 717, Nb was 332.1 (291.6 - 380.6). Here we see that when considered all of the successful parents above Detroit together, the Nb results are not so problematic. The ratio of Nb to number of successful parents is a more reasonable ~69% (compared to 95% for outplants and 92% for reintros). 


# Appendix

We already have allele frequencies and HWE from many places, but let's be consistent and calculate using GENEPOP. This requires conversion to GENEPOP format.

```{r}
offspring2020 <- pedigree_meta %>%
  filter(offspring_year == 2020) %>%
  pull(offspring_sample_id)

gts_of_2020 <- full_meta %>%
  filter(sample_id %in% offspring2020) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_of_2020 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_of_2020 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_of_2020[,3:ncol(gts_of_2020)],pops = gts_of_2020$pop,ind.ids = gts_of_2020$sample_id,folder = "analysis/genepop/",filename ="genepop_2020.txt",ncode = 3,diploid = T)
```

```{r, message = FALSE, warning=FALSE}
offspring2017 <- pedigree_meta %>%
  filter(offspring_year == 2017) %>%
  pull(offspring_sample_id)

gts_of_2017 <- full_meta %>%
  filter(sample_id %in% offspring2017) %>%
  select(sample_id, starts_with(c("Ot", "Ogo", "SSa"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_of_2017 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_of_2017 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

#write_genepop_zlr(loci = gts_of_2017[,3:ncol(gts_of_2017)],pops = gts_of_2017$pop,ind.ids = gts_of_2017$sample_id,folder = "analysis/genepop/",filename ="genepop_2017.txt",ncode = 3,diploid = T)
```
